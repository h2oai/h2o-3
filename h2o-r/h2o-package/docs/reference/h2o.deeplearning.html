<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Build a Deep Neural Network model using CPUs
Builds a feed-forward multilayer artificial neural network on an H2OFrame — h2o.deeplearning • h2o</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  <link href="../extra.css" rel="stylesheet">
  <script src="../extra.js"></script>
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">h2o</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Using
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../articles/basics.html">H2O Basics</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/h2oai/h2o-3">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Build a Deep Neural Network model using CPUs
Builds a feed-forward multilayer artificial neural network on an H2OFrame</h1>
    </div>

    
    <p>Build a Deep Neural Network model using CPUs
Builds a feed-forward multilayer artificial neural network on an H2OFrame</p>
    

    <pre class="usage"><span class='fu'>h2o.deeplearning</span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='no'>training_frame</span>, <span class='kw'>model_id</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>validation_frame</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>nfolds</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>keep_cross_validation_predictions</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>keep_cross_validation_fold_assignment</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>fold_assignment</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>,
  <span class='st'>"Random"</span>, <span class='st'>"Modulo"</span>, <span class='st'>"Stratified"</span>), <span class='kw'>fold_column</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>ignore_const_cols</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>score_each_iteration</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>weights_column</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>offset_column</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>balance_classes</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>class_sampling_factors</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>max_after_balance_size</span> <span class='kw'>=</span> <span class='fl'>5</span>,
  <span class='kw'>max_hit_ratio_k</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>checkpoint</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>pretrained_autoencoder</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>overwrite_with_best_model</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>use_all_factor_levels</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>standardize</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>activation</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"Tanh"</span>, <span class='st'>"TanhWithDropout"</span>, <span class='st'>"Rectifier"</span>,
  <span class='st'>"RectifierWithDropout"</span>, <span class='st'>"Maxout"</span>, <span class='st'>"MaxoutWithDropout"</span>), <span class='kw'>hidden</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>200</span>,
  <span class='fl'>200</span>), <span class='kw'>epochs</span> <span class='kw'>=</span> <span class='fl'>10</span>, <span class='kw'>train_samples_per_iteration</span> <span class='kw'>=</span> -<span class='fl'>2</span>,
  <span class='kw'>target_ratio_comm_to_comp</span> <span class='kw'>=</span> <span class='fl'>0.05</span>, <span class='kw'>seed</span> <span class='kw'>=</span> -<span class='fl'>1</span>, <span class='kw'>adaptive_rate</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>rho</span> <span class='kw'>=</span> <span class='fl'>0.99</span>, <span class='kw'>epsilon</span> <span class='kw'>=</span> <span class='fl'>1e-08</span>, <span class='kw'>rate</span> <span class='kw'>=</span> <span class='fl'>0.005</span>, <span class='kw'>rate_annealing</span> <span class='kw'>=</span> <span class='fl'>1e-06</span>,
  <span class='kw'>rate_decay</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>momentum_start</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>momentum_ramp</span> <span class='kw'>=</span> <span class='fl'>1e+06</span>,
  <span class='kw'>momentum_stable</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>nesterov_accelerated_gradient</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>input_dropout_ratio</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>hidden_dropout_ratios</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>l1</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>l2</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>max_w2</span> <span class='kw'>=</span> <span class='fl'>3.4028235e+38</span>, <span class='kw'>initial_weight_distribution</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"UniformAdaptive"</span>,
  <span class='st'>"Uniform"</span>, <span class='st'>"Normal"</span>), <span class='kw'>initial_weight_scale</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>initial_weights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>initial_biases</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>loss</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"Automatic"</span>, <span class='st'>"CrossEntropy"</span>, <span class='st'>"Quadratic"</span>,
  <span class='st'>"Huber"</span>, <span class='st'>"Absolute"</span>, <span class='st'>"Quantile"</span>), <span class='kw'>distribution</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>, <span class='st'>"bernoulli"</span>,
  <span class='st'>"multinomial"</span>, <span class='st'>"gaussian"</span>, <span class='st'>"poisson"</span>, <span class='st'>"gamma"</span>, <span class='st'>"tweedie"</span>, <span class='st'>"laplace"</span>,
  <span class='st'>"quantile"</span>, <span class='st'>"huber"</span>), <span class='kw'>quantile_alpha</span> <span class='kw'>=</span> <span class='fl'>0.5</span>, <span class='kw'>tweedie_power</span> <span class='kw'>=</span> <span class='fl'>1.5</span>,
  <span class='kw'>huber_alpha</span> <span class='kw'>=</span> <span class='fl'>0.9</span>, <span class='kw'>score_interval</span> <span class='kw'>=</span> <span class='fl'>5</span>, <span class='kw'>score_training_samples</span> <span class='kw'>=</span> <span class='fl'>10000</span>,
  <span class='kw'>score_validation_samples</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>score_duty_cycle</span> <span class='kw'>=</span> <span class='fl'>0.1</span>,
  <span class='kw'>classification_stop</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>regression_stop</span> <span class='kw'>=</span> <span class='fl'>1e-06</span>, <span class='kw'>stopping_rounds</span> <span class='kw'>=</span> <span class='fl'>5</span>,
  <span class='kw'>stopping_metric</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>, <span class='st'>"deviance"</span>, <span class='st'>"logloss"</span>, <span class='st'>"MSE"</span>, <span class='st'>"RMSE"</span>, <span class='st'>"MAE"</span>,
  <span class='st'>"RMSLE"</span>, <span class='st'>"AUC"</span>, <span class='st'>"lift_top_group"</span>, <span class='st'>"misclassification"</span>,
  <span class='st'>"mean_per_class_error"</span>), <span class='kw'>stopping_tolerance</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>max_runtime_secs</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>score_validation_sampling</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"Uniform"</span>, <span class='st'>"Stratified"</span>),
  <span class='kw'>diagnostics</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>fast_mode</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>force_load_balance</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>variable_importances</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>replicate_training_data</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>single_node_mode</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>shuffle_training_data</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>missing_values_handling</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"MeanImputation"</span>, <span class='st'>"Skip"</span>), <span class='kw'>quiet_mode</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>autoencoder</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>sparse</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>col_major</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>average_activation</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>sparsity_beta</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>max_categorical_features</span> <span class='kw'>=</span> <span class='fl'>2147483647</span>, <span class='kw'>reproducible</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>export_weights_and_biases</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>mini_batch_size</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>categorical_encoding</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"AUTO"</span>, <span class='st'>"Enum"</span>, <span class='st'>"OneHotInternal"</span>, <span class='st'>"OneHotExplicit"</span>,
  <span class='st'>"Binary"</span>, <span class='st'>"Eigen"</span>, <span class='st'>"LabelEncoder"</span>, <span class='st'>"SortByResponse"</span>, <span class='st'>"EnumLimited"</span>),
  <span class='kw'>elastic_averaging</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>elastic_averaging_moving_rate</span> <span class='kw'>=</span> <span class='fl'>0.9</span>,
  <span class='kw'>elastic_averaging_regularization</span> <span class='kw'>=</span> <span class='fl'>0.001</span>, <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p></td>
    </tr>
    <tr>
      <th>y</th>
      <td><p>The name or column index of the response variable in the data. The response must be either a numeric or a
categorical/factor variable. If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p></td>
    </tr>
    <tr>
      <th>training_frame</th>
      <td><p>Id of the training data frame.</p></td>
    </tr>
    <tr>
      <th>model_id</th>
      <td><p>Destination id for this model; auto-generated if not specified.</p></td>
    </tr>
    <tr>
      <th>validation_frame</th>
      <td><p>Id of the validation data frame.</p></td>
    </tr>
    <tr>
      <th>nfolds</th>
      <td><p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>keep_cross_validation_predictions</th>
      <td><p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>keep_cross_validation_fold_assignment</th>
      <td><p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>fold_assignment</th>
      <td><p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: "AUTO",
"Random", "Modulo", "Stratified". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>fold_column</th>
      <td><p>Column with cross-validation fold index assignment per observation.</p></td>
    </tr>
    <tr>
      <th>ignore_const_cols</th>
      <td><p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>score_each_iteration</th>
      <td><p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>weights_column</th>
      <td><p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor.</p></td>
    </tr>
    <tr>
      <th>offset_column</th>
      <td><p>Offset column. This will be added to the combination of columns before applying the link function.</p></td>
    </tr>
    <tr>
      <th>balance_classes</th>
      <td><p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p></td>
    </tr>
    <tr>
      <th>class_sampling_factors</th>
      <td><p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p></td>
    </tr>
    <tr>
      <th>max_after_balance_size</th>
      <td><p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p></td>
    </tr>
    <tr>
      <th>max_hit_ratio_k</th>
      <td><p>Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable).
Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>checkpoint</th>
      <td><p>Model checkpoint to resume training with.</p></td>
    </tr>
    <tr>
      <th>pretrained_autoencoder</th>
      <td><p>Pretrained autoencoder model to initialize this model with.</p></td>
    </tr>
    <tr>
      <th>overwrite_with_best_model</th>
      <td><p><code>Logical</code>. If enabled, override the final model with the best model found during training. Defaults to
TRUE.</p></td>
    </tr>
    <tr>
      <th>use_all_factor_levels</th>
      <td><p><code>Logical</code>. Use all factor levels of categorical variables. Otherwise, the first factor level is omitted
(without loss of accuracy). Useful for variable importances and auto-enabled for autoencoder. Defaults to
TRUE.</p></td>
    </tr>
    <tr>
      <th>standardize</th>
      <td><p><code>Logical</code>. If enabled, automatically standardize the data. If disabled, the user must provide properly
scaled input data. Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>activation</th>
      <td><p>Activation function. Must be one of: "Tanh", "TanhWithDropout", "Rectifier", "RectifierWithDropout", "Maxout",
"MaxoutWithDropout". Defaults to Rectifier.</p></td>
    </tr>
    <tr>
      <th>hidden</th>
      <td><p>Hidden layer sizes (e.g. [100, 100]). Defaults to [200, 200].</p></td>
    </tr>
    <tr>
      <th>epochs</th>
      <td><p>How many times the dataset should be iterated (streamed), can be fractional. Defaults to 10.</p></td>
    </tr>
    <tr>
      <th>train_samples_per_iteration</th>
      <td><p>Number of training samples (globally) per MapReduce iteration. Special values are 0: one epoch, -1: all
available data (e.g., replicated training data), -2: automatic. Defaults to -2.</p></td>
    </tr>
    <tr>
      <th>target_ratio_comm_to_comp</th>
      <td><p>Target ratio of communication overhead to computation. Only for multi-node operation and
train_samples_per_iteration = -2 (auto-tuning). Defaults to 0.05.</p></td>
    </tr>
    <tr>
      <th>seed</th>
      <td><p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default)
Note: only reproducible when running single threaded.
Defaults to -1 (time-based random number).</p></td>
    </tr>
    <tr>
      <th>adaptive_rate</th>
      <td><p><code>Logical</code>. Adaptive learning rate. Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>rho</th>
      <td><p>Adaptive learning rate time decay factor (similarity to prior updates). Defaults to 0.99.</p></td>
    </tr>
    <tr>
      <th>epsilon</th>
      <td><p>Adaptive learning rate smoothing factor (to avoid divisions by zero and allow progress). Defaults to 1e-08.</p></td>
    </tr>
    <tr>
      <th>rate</th>
      <td><p>Learning rate (higher =&gt; less stable, lower =&gt; slower convergence). Defaults to 0.005.</p></td>
    </tr>
    <tr>
      <th>rate_annealing</th>
      <td><p>Learning rate annealing: rate / (1 + rate_annealing * samples). Defaults to 1e-06.</p></td>
    </tr>
    <tr>
      <th>rate_decay</th>
      <td><p>Learning rate decay factor between layers (N-th layer: rate * rate_decay ^ (n - 1). Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>momentum_start</th>
      <td><p>Initial momentum at the beginning of training (try 0.5). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>momentum_ramp</th>
      <td><p>Number of training samples for which momentum increases. Defaults to 1000000.</p></td>
    </tr>
    <tr>
      <th>momentum_stable</th>
      <td><p>Final momentum after the ramp is over (try 0.99). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>nesterov_accelerated_gradient</th>
      <td><p><code>Logical</code>. Use Nesterov accelerated gradient (recommended). Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>input_dropout_ratio</th>
      <td><p>Input layer dropout ratio (can improve generalization, try 0.1 or 0.2). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>hidden_dropout_ratios</th>
      <td><p>Hidden layer dropout ratios (can improve generalization), specify one value per hidden layer, defaults to 0.5.</p></td>
    </tr>
    <tr>
      <th>l1</th>
      <td><p>L1 regularization (can add stability and improve generalization, causes many weights to become 0). Defaults to
0.</p></td>
    </tr>
    <tr>
      <th>l2</th>
      <td><p>L2 regularization (can add stability and improve generalization, causes many weights to be small. Defaults to
0.</p></td>
    </tr>
    <tr>
      <th>max_w2</th>
      <td><p>Constraint for squared sum of incoming weights per unit (e.g. for Rectifier). Defaults to 3.4028235e+38.</p></td>
    </tr>
    <tr>
      <th>initial_weight_distribution</th>
      <td><p>Initial weight distribution. Must be one of: "UniformAdaptive", "Uniform", "Normal". Defaults to
UniformAdaptive.</p></td>
    </tr>
    <tr>
      <th>initial_weight_scale</th>
      <td><p>Uniform: -value...value, Normal: stddev. Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>initial_weights</th>
      <td><p>A list of H2OFrame ids to initialize the weight matrices of this model with.</p></td>
    </tr>
    <tr>
      <th>initial_biases</th>
      <td><p>A list of H2OFrame ids to initialize the bias vectors of this model with.</p></td>
    </tr>
    <tr>
      <th>loss</th>
      <td><p>Loss function. Must be one of: "Automatic", "CrossEntropy", "Quadratic", "Huber", "Absolute", "Quantile".
Defaults to Automatic.</p></td>
    </tr>
    <tr>
      <th>distribution</th>
      <td><p>Distribution function Must be one of: "AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
"tweedie", "laplace", "quantile", "huber". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>quantile_alpha</th>
      <td><p>Desired quantile for Quantile regression, must be between 0 and 1. Defaults to 0.5.</p></td>
    </tr>
    <tr>
      <th>tweedie_power</th>
      <td><p>Tweedie power for Tweedie regression, must be between 1 and 2. Defaults to 1.5.</p></td>
    </tr>
    <tr>
      <th>huber_alpha</th>
      <td><p>Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and
1). Defaults to 0.9.</p></td>
    </tr>
    <tr>
      <th>score_interval</th>
      <td><p>Shortest time interval (in seconds) between model scoring. Defaults to 5.</p></td>
    </tr>
    <tr>
      <th>score_training_samples</th>
      <td><p>Number of training set samples for scoring (0 for all). Defaults to 10000.</p></td>
    </tr>
    <tr>
      <th>score_validation_samples</th>
      <td><p>Number of validation set samples for scoring (0 for all). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>score_duty_cycle</th>
      <td><p>Maximum duty cycle fraction for scoring (lower: more training, higher: more scoring). Defaults to 0.1.</p></td>
    </tr>
    <tr>
      <th>classification_stop</th>
      <td><p>Stopping criterion for classification error fraction on training data (-1 to disable). Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>regression_stop</th>
      <td><p>Stopping criterion for regression error (MSE) on training data (-1 to disable). Defaults to 1e-06.</p></td>
    </tr>
    <tr>
      <th>stopping_rounds</th>
      <td><p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 5.</p></td>
    </tr>
    <tr>
      <th>stopping_metric</th>
      <td><p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression) Must be one of:
"AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE", "AUC", "lift_top_group", "misclassification",
"mean_per_class_error". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>stopping_tolerance</th>
      <td><p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>max_runtime_secs</th>
      <td><p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>score_validation_sampling</th>
      <td><p>Method used to sample validation dataset for scoring. Must be one of: "Uniform", "Stratified". Defaults to
Uniform.</p></td>
    </tr>
    <tr>
      <th>diagnostics</th>
      <td><p><code>Logical</code>. Enable diagnostics for hidden layers. Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>fast_mode</th>
      <td><p><code>Logical</code>. Enable fast mode (minor approximation in back-propagation). Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>force_load_balance</th>
      <td><p><code>Logical</code>. Force extra load balancing to increase training speed for small datasets (to keep all cores
busy). Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>variable_importances</th>
      <td><p><code>Logical</code>. Compute variable importances for input features (Gedeon method) - can be slow for large
networks. Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>replicate_training_data</th>
      <td><p><code>Logical</code>. Replicate the entire training dataset onto every node for faster training on small datasets.
Defaults to TRUE.</p></td>
    </tr>
    <tr>
      <th>single_node_mode</th>
      <td><p><code>Logical</code>. Run on a single node for fine-tuning of model parameters. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>shuffle_training_data</th>
      <td><p><code>Logical</code>. Enable shuffling of training data (recommended if training data is replicated and
train_samples_per_iteration is close to #nodes x #rows, of if using balance_classes). Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>missing_values_handling</th>
      <td><p>Handling of missing values. Either MeanImputation or Skip. Must be one of: "MeanImputation", "Skip". Defaults
to MeanImputation.</p></td>
    </tr>
    <tr>
      <th>quiet_mode</th>
      <td><p><code>Logical</code>. Enable quiet mode for less output to standard output. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>autoencoder</th>
      <td><p><code>Logical</code>. Auto-Encoder. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>sparse</th>
      <td><p><code>Logical</code>. Sparse data handling (more efficient for data with lots of 0 values). Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>col_major</th>
      <td><p><code>Logical</code>. #DEPRECATED Use a column major weight matrix for input layer. Can speed up forward
propagation, but might slow down backpropagation. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>average_activation</th>
      <td><p>Average activation for sparse auto-encoder. #Experimental Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>sparsity_beta</th>
      <td><p>Sparsity regularization. #Experimental Defaults to 0.</p></td>
    </tr>
    <tr>
      <th>max_categorical_features</th>
      <td><p>Max. number of categorical features, enforced via hashing. #Experimental Defaults to 2147483647.</p></td>
    </tr>
    <tr>
      <th>reproducible</th>
      <td><p><code>Logical</code>. Force reproducibility on small data (will be slow - only uses 1 thread). Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>export_weights_and_biases</th>
      <td><p><code>Logical</code>. Whether to export Neural Network weights and biases to H2O Frames. Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>mini_batch_size</th>
      <td><p>Mini-batch size (smaller leads to better fit, larger can speed up and generalize better). Defaults to 1.</p></td>
    </tr>
    <tr>
      <th>categorical_encoding</th>
      <td><p>Encoding scheme for categorical features Must be one of: "AUTO", "Enum", "OneHotInternal", "OneHotExplicit",
"Binary", "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited". Defaults to AUTO.</p></td>
    </tr>
    <tr>
      <th>elastic_averaging</th>
      <td><p><code>Logical</code>. Elastic averaging between compute nodes can improve distributed model convergence.
#Experimental Defaults to FALSE.</p></td>
    </tr>
    <tr>
      <th>elastic_averaging_moving_rate</th>
      <td><p>Elastic averaging moving rate (only if elastic averaging is enabled). Defaults to 0.9.</p></td>
    </tr>
    <tr>
      <th>elastic_averaging_regularization</th>
      <td><p>Elastic averaging regularization strength (only if elastic averaging is enabled). Defaults to 0.001.</p></td>
    </tr>
    <tr>
      <th>verbose</th>
      <td><p><code>Logical</code>. Print scoring history to the console (Metrics per tree for GBM, DRF, &amp; XGBoost. Metrics per epoch for Deep Learning). Defaults to FALSE.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <p><code><a href='predict.H2OModel.html'>predict.H2OModel</a></code> for prediction</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'>library</span>(<span class='no'>h2o</span>)
<span class='fu'><a href='h2o.init.html'>h2o.init</a></span>()</div><div class='output co'>#&gt; Reading in config file: ./../../../../.h2oconfig
#&gt; 
#&gt; H2O is not running yet, starting it now...</div><div class='output co'>#&gt; <span class='warning'>Warning: cannot open file '/Users/terrytangyuan/h2o-3/h2o-r/h2o/branch.txt': No such file or directory</span></div><div class='output co'>#&gt; <span class='error'>Error in file(con, "r"): cannot open the connection</span></div><div class='input'><span class='no'>iris.hex</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='as.h2o.html'>as.h2o</a></span>(<span class='no'>iris</span>)</div><div class='output co'>#&gt; <span class='error'>Error in h2o.getConnection(): No active connection to an H2O cluster. Did you run `h2o.init()` ?</span></div><div class='input'><span class='no'>iris.dl</span> <span class='kw'>&lt;-</span> <span class='fu'>h2o.deeplearning</span>(<span class='kw'>x</span> <span class='kw'>=</span> <span class='fl'>1</span>:<span class='fl'>4</span>, <span class='kw'>y</span> <span class='kw'>=</span> <span class='fl'>5</span>, <span class='kw'>training_frame</span> <span class='kw'>=</span> <span class='no'>iris.hex</span>, <span class='kw'>seed</span><span class='kw'>=</span><span class='fl'>123456</span>)</div><div class='output co'>#&gt; <span class='error'>Error in is.H2OFrame(training_frame): object 'iris.hex' not found</span></div><div class='input'>
<span class='co'># now make a prediction</span>
<span class='no'>predictions</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='predict.H2OModel.html'>h2o.predict</a></span>(<span class='no'>iris.dl</span>, <span class='no'>iris.hex</span>)</div><div class='output co'>#&gt; <span class='error'>Error in h2o.predict(iris.dl, iris.hex): object 'iris.dl' not found</span></div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by The H2O.ai team.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
