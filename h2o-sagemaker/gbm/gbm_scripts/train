#!/usr/bin/env python3

"""
Simple example that integrates H2o AutoML functionality with Amazon Sagemaker.
AutoML docs are over at:
http://h2o-release.s3.amazonaws.com/h2o/rel-wheeler/2/docs-website/h2o-docs/automl.html

This implementation works in File mode and makes no assumptions about the input
file names. Input is specified as CSV with a data point in each row, the label
column is specified via an optional hyperparamter - 'target', inside the
'training_params' dictionary. If there's no target specified, we default to
'label' as the target variable for the data.

The hyperparameters.json file needs to have content similar to ->
{
'training': {
                'classification': 'true',
                'target': 'response',
            },
'h2o': { Insert any H2O specific parameters here },
'aml': { Insert any parameters you want to specify for AutoML here -
        docs: http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html}
}

"""

from __future__ import print_function

import json
import os
import sys
import traceback
import time
import socket
from collections import Counter
import h2o
import helper_functions
from h2o.estimators.gbm import H2OGradientBoostingEstimator


def _connect_to_cluster():
    print("Creating Connection to H2O-3")
    h2o_launched = False
    i = 0
    while h2o_launched is False:
        try:
            s = socket.socket()
            s.connect(("127.0.0.1", 54321))
            h2o_launched = True
        except Exception as e:
            time.sleep(6)
            if i % 5 == 0:
                print("Attempt {}: H2O-3 not running yet...".format(i))
            if i > 30:
                raise Exception("""Could not connect to H2O Cluster in {} attempts
                                   Last Error: {}""".format(i, e))
            i += 1
        finally:
            s.close()

    h2o.connect(url="http://127.0.0.1:54321")


def _get_data(channel_name):
    prefix = "/opt/ml/"
    input_path = prefix + 'input/data'
    training_path = os.path.join(input_path, channel_name)
    data_files = [os.path.join(training_path, filename)
                  for filename in os.listdir(training_path)
                  if not filename.startswith(".")]
    if len(data_files) == 0:
        raise ValueError(('There are no files in {}.\n' +
                          'This usually indicates that the channel ({}) '
                          'was incorrectly specified,\n' +
                          'the data specification in S3 was incorrectly '
                          'specified or the role specified\n' +
                          'does not have permission to access the '
                          'data.').format(training_path, channel_name))
    elif len(data_files) == 1:
        import_data = h2o.import_file(data_files[0])
    else:
        prefix = os.path.commonprefix(data_files)
        suffix_counter = Counter()
        for filename in data_files:
            suffix_counter[filename.split(".")[-1]] += 1
        suffix = suffix_counter.most_common(1)[0][0]
        import_data = h2o.import_file(path=training_path,
                                      pattern="{}.*\{}".format(prefix, suffix))

    return import_data


def _train_model(hyperparameters={}, resource_params={}):
    training_params_str, gbm_params = helper_functions._parse_hyperparameters(hyperparameters)
    training_params = json.loads(training_params_str)
    prefix = "/opt/ml/"
    output_path = os.path.join(prefix, 'output')
    model_path = os.path.join(prefix, 'model')

    gbm_params['distribution'] = training_params['distribution']

    print("Beginning Model Training")
    try:
        response_label = training_params.get('target')
        categorical_columns = training_params.get("categorical_columns", []).split(",")
        train_data = _get_data('training')

        X = train_data.columns
        y = response_label

        # We don't want the target column present in the training
        try:
            X.remove(y)
        except ValueError:
            raise ValueError('Incorrect target - column "%s" does not exist in the data!' % response_label)

        print("Setting Response Column to Categorical based on family: {}".format(training_params.get('distribution', 'AUTO')))
        if training_params.get('distribution', 'AUTO') in ['bernoulli', 'multinomial']:
            print("Family is {}: setting target value to categorical".format(training_params.get('distribution', 'AUTO')))
            train_data[y] = train_data[y].asfactor()
        else:
            print("Family is {}: Value can be continous. Nothing to do".format(training_params.get('family', 'AUTO')))

        print("Converting specified columns to categorical values:")
        print(categorical_columns)
        for col in categorical_columns:
            train_data[col] = train_data[col].asfactor()

        gbm_model = H2OGradientBoostingEstimator(**gbm_params)
        gbm_model.train(x=X, y=y, training_frame=train_data)

        print(gbm_model.model_performance())

        model_path = h2o.save_model(gbm_model, path=model_path)
        print("Model Path with Name: {}".format(model_path))
        print('Training complete.')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason
        # in the DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)

        # Printing this causes the exception to be in the training job logs
        print('Exception during training: ' + str(e) + '\n' + trc,
              file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)


def main():
    hyperparameters, resource_params = helper_functions._get_parameters()
    helper_functions._create_h2o_cluster(resource_params)
    if resource_params["current_host"] == resource_params["hosts"][0]:
        _connect_to_cluster()
        _train_model(hyperparameters, resource_params)


if __name__ == '__main__':
    main()
    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
