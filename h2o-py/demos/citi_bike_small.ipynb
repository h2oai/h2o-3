{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "name": "",
  "signature": "sha256:589bf3c8a8217beb63e3e57f13e416f318f484e5a2491845b01c92ddd9b00936"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import h2o"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Explore a typical Data Science workflow with H2O and Python\n",
      "#\n",
      "# Goal: assist the manager of CitiBike of NYC to load-balance the bicycles\n",
      "# across the CitiBike network of stations, by predicting the number of bike\n",
      "# trips taken from the station every day.  Use 10 million rows of historical\n",
      "# data, and eventually add weather data.\n",
      "\n",
      "\n",
      "# Connect to a cluster\n",
      "h2o.init()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pick either the big or the small demo.\n",
      "# Big data is 10M rows\n",
      "small_test = [h2o.locate(\"bigdata/laptop/citibike-nyc/2013-10.csv\")]\n",
      "big_test =   [h2o.locate(\"bigdata/laptop/citibike-nyc/2013-07.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2013-08.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2013-09.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2013-10.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2013-11.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2013-12.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-01.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-02.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-03.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-04.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-05.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-06.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-07.csv\"),\n",
      "              h2o.locate(\"bigdata/laptop/citibike-nyc/2014-08.csv\")]\n",
      "\n",
      "# ----------\n",
      "\n",
      "# 1- Load data - 1 row per bicycle trip.  Has columns showing the start and end\n",
      "# station, trip duration and trip start time and day.  The larger dataset\n",
      "# totals about 10 million rows\n",
      "print \"Import and Parse bike data\"\n",
      "data = h2o.import_frame(path=small_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ----------\n",
      "\n",
      "# 2- light data munging: group the bike starts per-day, converting the 10M rows\n",
      "# of trips to about 140,000 station&day combos - predicting the number of trip\n",
      "# starts per-station-per-day.\n",
      "\n",
      "# Convert start time to: Day since the Epoch\n",
      "startime = data[\"starttime\"]\n",
      "secsPerDay=1000*60*60*24\n",
      "data[\"Days\"] = (startime/secsPerDay).floor()\n",
      "data.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now do a monster Group-By.  Count bike starts per-station per-day.  Ends up\n",
      "# with about 340 stations times 400 days (140,000 rows).  This is what we want\n",
      "# to predict.\n",
      "by = [\"Days\",\"start station name\"]\n",
      "aggregates = {\"bikes\": [\"count\", 0, \"all\"]}\n",
      "bpd = h2o.group_by(data, cols=by, aggregates=aggregates) # Compute bikes-per-day\n",
      "bpd.show()\n",
      "bpd.describe()\n",
      "bpd.dim()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Quantiles: the data is fairly unbalanced; some station/day combos are wildly\n",
      "# more popular than others.\n",
      "print \"Quantiles of bikes-per-day\"\n",
      "bpd[\"bikes\"].quantile().show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A little feature engineering\n",
      "# Add in month-of-year (seasonality; fewer bike rides in winter than summer)\n",
      "secs = bpd[\"Days\"]*secsPerDay\n",
      "bpd[\"Month\"]     = secs.month().asfactor()\n",
      "# Add in day-of-week (work-week; more bike rides on Sunday than Monday)\n",
      "bpd[\"DayOfWeek\"] = secs.dayOfWeek()\n",
      "print \"Bikes-Per-Day\"\n",
      "bpd.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ----------\n",
      "# 3- Fit a model on train; using test as validation\n",
      "\n",
      "# Function for doing class test/train/holdout split\n",
      "def split_fit_predict(data):\n",
      "  global gbm0,drf0,glm0\n",
      "  # Classic Test/Train split\n",
      "  r = data['Days'].runif()   # Random UNIForm numbers, one per row\n",
      "  train = data[  r  < 0.6]\n",
      "  test  = data[(0.6 <= r) & (r < 0.9)]\n",
      "  hold  = data[ 0.9 <= r ]\n",
      "  print \"Training data has\",train.ncol(),\"columns and\",train.nrow(),\"rows, test has\",test.nrow(),\"rows, holdout has\",hold.nrow()\n",
      "  \n",
      "  # Run GBM\n",
      "  gbm0 = h2o.gbm(x           =train.drop(\"bikes\"),\n",
      "                 y           =train     [\"bikes\"],\n",
      "                 validation_x=test .drop(\"bikes\"),\n",
      "                 validation_y=test      [\"bikes\"],\n",
      "                 ntrees=500, # 500 works well\n",
      "                 max_depth=6,\n",
      "                 learn_rate=0.1)\n",
      "\n",
      "  # Run DRF\n",
      "  drf0 = h2o.random_forest(x =train.drop(\"bikes\"),\n",
      "                y           =train     [\"bikes\"],\n",
      "                validation_x=test .drop(\"bikes\"),\n",
      "                validation_y=test      [\"bikes\"],\n",
      "                ntrees=250,\n",
      "                max_depth=30)\n",
      "\n",
      "  # Run GLM\n",
      "  glm0 = h2o.glm(x           =train.drop(\"bikes\"),\n",
      "                 y           =train     [\"bikes\"],\n",
      "                 validation_x=test .drop(\"bikes\"),\n",
      "                 validation_y=test      [\"bikes\"],\n",
      "                 drop_na20_cols=True,\n",
      "                 Lambda=[1e-5],\n",
      "                 family=\"poisson\")\n",
      "  \n",
      "  # Run DL\n",
      "  dl0 = h2o.deeplearning(x  =train.drop(\"bikes\"),\n",
      "                y           =train     [\"bikes\"],\n",
      "                validation_x=test .drop(\"bikes\"),\n",
      "                validation_y=test      [\"bikes\"],\n",
      "                drop_na20_cols=True,\n",
      "                hidden=[50,50,50,50],\n",
      "                epochs=50)\n",
      "  \n",
      "  # ----------\n",
      "  # 4- Score on holdout set & report\n",
      "  train_r2_gbm = gbm0.model_performance(train).r2()\n",
      "  test_r2_gbm  = gbm0.model_performance(test ).r2()\n",
      "  hold_r2_gbm  = gbm0.model_performance(hold ).r2()\n",
      "  print \"GBM R2 TRAIN=\",train_r2_gbm,\", R2 TEST=\",test_r2_gbm,\", R2 HOLDOUT=\",hold_r2_gbm\n",
      "  \n",
      "  train_r2_drf = drf0.model_performance(train).r2()\n",
      "  test_r2_drf  = drf0.model_performance(test ).r2()\n",
      "  hold_r2_drf  = drf0.model_performance(hold ).r2()\n",
      "  print \"DRF R2 TRAIN=\",train_r2_drf,\", R2 TEST=\",test_r2_drf,\", R2 HOLDOUT=\",hold_r2_drf\n",
      "  \n",
      "  train_r2_glm = glm0.model_performance(train).r2()\n",
      "  test_r2_glm  = glm0.model_performance(test ).r2()\n",
      "  hold_r2_glm  = glm0.model_performance(hold ).r2()\n",
      "  print \"GLM R2 TRAIN=\",train_r2_glm,\", R2 TEST=\",test_r2_glm,\", R2 HOLDOUT=\",hold_r2_glm\n",
      "    \n",
      "  train_r2_dl = dl0.model_performance(train).r2()\n",
      "  test_r2_dl  = dl0.model_performance(test ).r2()\n",
      "  hold_r2_dl  = dl0.model_performance(hold ).r2()\n",
      "  print \" DL R2 TRAIN=\",train_r2_dl,\", R2 TEST=\",test_r2_dl,\", R2 HOLDOUT=\",hold_r2_dl\n",
      "  # --------------"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split the data (into test & train), fit some models and predict on the holdout data\n",
      "split_fit_predict(bpd)\n",
      "# Here we see an r^2 of 0.91 for GBM, and 0.71 for GLM.  This means given just\n",
      "# the station, the month, and the day-of-week we can predict 90% of the\n",
      "# variance of the bike-trip-starts."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ----------\n",
      "# 5- Now lets add some weather\n",
      "# Load weather data\n",
      "wthr1 = h2o.import_frame(path=[h2o.locate(\"bigdata/laptop/citibike-nyc/31081_New_York_City__Hourly_2013.csv\"),\n",
      "                               h2o.locate(\"bigdata/laptop/citibike-nyc/31081_New_York_City__Hourly_2014.csv\")])\n",
      "# Peek at the data\n",
      "wthr1.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lots of columns in there!  Lets plan on converting to time-since-epoch to do\n",
      "# a 'join' with the bike data, plus gather weather info that might affect\n",
      "# cyclists - rain, snow, temperature.  Alas, drop the \"snow\" column since it's\n",
      "# all NA's.  Also add in dew point and humidity just in case.  Slice out just\n",
      "# the columns of interest and drop the rest.\n",
      "wthr2 = wthr1[\"Year Local\",\"Month Local\",\"Day Local\",\"Hour Local\",\"Dew Point (C)\",\"Humidity Fraction\",\"Precipitation One Hour (mm)\",\"Temperature (C)\",\"Weather Code 1/ Description\"]\n",
      "wthr2[\"Precipitation One Hour (mm)\"]._name = \"Rain (mm)\" # Shorter column name\n",
      "wthr2[\"Weather Code 1/ Description\"]._name = \"WC1\" # Shorter column name\n",
      "wthr2.describe()\n",
      "# Much better!  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Filter down to the weather at Noon\n",
      "wthr3 = wthr2[ wthr2[\"Hour Local\"]==12 ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets now get Days since the epoch... we'll convert year/month/day into Epoch\n",
      "# time, and then back to Epoch days.  Need zero-based month and days, but have\n",
      "# 1-based.\n",
      "wthr3[\"msec\"] = h2o.H2OVec.mktime(year=wthr3[\"Year Local\"], month=wthr3[\"Month Local\"]-1, day=wthr3[\"Day Local\"]-1, hour=wthr3[\"Hour Local\"])\n",
      "secsPerDay=1000*60*60*24\n",
      "wthr3[\"Days\"] = (wthr3[\"msec\"]/secsPerDay).floor()\n",
      "wthr3.describe()\n",
      "# msec looks sane (numbers like 1.3e12 are in the correct range for msec since\n",
      "# 1970).  Epoch Days matches closely with the epoch day numbers from the\n",
      "# CitiBike dataset.  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Lets drop off the extra time columns to make a easy-to-handle dataset.\n",
      "wthr4 = wthr3.drop(\"Year Local\").drop(\"Month Local\").drop(\"Day Local\").drop(\"Hour Local\").drop(\"msec\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Also, most rain numbers are missing - lets assume those are zero rain days\n",
      "rain = wthr4[\"Rain (mm)\"]\n",
      "rain[rain == None ] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ----------\n",
      "# 6 - Join the weather data-per-day to the bike-starts-per-day\n",
      "print \"Merge Daily Weather with Bikes-Per-Day\"\n",
      "bpd_with_weather = bpd.merge(wthr4,allLeft=True,allRite=False)\n",
      "bpd_with_weather.describe()\n",
      "bpd_with_weather.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 7 - Test/Train split again, model build again, this time with weather\n",
      "split_fit_predict(bpd_with_weather)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}