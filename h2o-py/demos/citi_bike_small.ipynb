{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore a typical Data Science workflow with H2O and Python\n",
    "#\n",
    "# Goal: assist the manager of CitiBike of NYC to load-balance the bicycles\n",
    "# across the CitiBike network of stations, by predicting the number of bike\n",
    "# trips taken from the station every day.  Use 10 million rows of historical\n",
    "# data, and eventually add weather data.\n",
    "\n",
    "\n",
    "# Connect to a cluster\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set this to True if you want to fetch the data directly from S3.\n",
    "# This is useful if your cluster is running in EC2.\n",
    "data_source_is_s3 = False\n",
    "\n",
    "def mylocate(s):\n",
    "    if data_source_is_s3:\n",
    "        return \"s3n://h2o-public-test-data/\" + s\n",
    "    else:\n",
    "        return h2o.locate(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pick either the big or the small demo.\n",
    "# Big data is 10M rows\n",
    "small_test = [mylocate(\"bigdata/laptop/citibike-nyc/2013-10.csv\")]\n",
    "big_test =   [mylocate(\"bigdata/laptop/citibike-nyc/2013-07.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2013-08.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2013-09.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2013-10.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2013-11.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2013-12.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-01.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-02.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-03.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-04.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-05.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-06.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-07.csv\"),\n",
    "              mylocate(\"bigdata/laptop/citibike-nyc/2014-08.csv\")]\n",
    "\n",
    "# ----------\n",
    "\n",
    "# 1- Load data - 1 row per bicycle trip.  Has columns showing the start and end\n",
    "# station, trip duration and trip start time and day.  The larger dataset\n",
    "# totals about 10 million rows\n",
    "print \"Import and Parse bike data\"\n",
    "data = h2o.import_file(path=small_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "\n",
    "# 2- light data munging: group the bike starts per-day, converting the 10M rows\n",
    "# of trips to about 140,000 station&day combos - predicting the number of trip\n",
    "# starts per-station-per-day.\n",
    "\n",
    "# Convert start time to: Day since the Epoch\n",
    "startime = data[\"starttime\"]\n",
    "secsPerDay=1000*60*60*24\n",
    "data[\"Days\"] = (startime/secsPerDay).floor()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now do a monster Group-By.  Count bike starts per-station per-day.  Ends up\n",
    "# with about 340 stations times 400 days (140,000 rows).  This is what we want\n",
    "# to predict.\n",
    "grouped = data.group_by([\"Days\",\"start station name\"])\n",
    "bpd = grouped.count().get_frame() # Compute bikes-per-day\n",
    "bpd.set_name(2,\"bikes\")\n",
    "bpd.show()\n",
    "bpd.describe()\n",
    "bpd.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quantiles: the data is fairly unbalanced; some station/day combos are wildly\n",
    "# more popular than others.\n",
    "print \"Quantiles of bikes-per-day\"\n",
    "bpd[\"bikes\"].quantile().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A little feature engineering\n",
    "# Add in month-of-year (seasonality; fewer bike rides in winter than summer)\n",
    "secs = bpd[\"Days\"]*secsPerDay\n",
    "bpd[\"Month\"]     = secs.month().asfactor()\n",
    "# Add in day-of-week (work-week; more bike rides on Sunday than Monday)\n",
    "bpd[\"DayOfWeek\"] = secs.dayOfWeek()\n",
    "print \"Bikes-Per-Day\"\n",
    "bpd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# 3- Fit a model on train; using test as validation\n",
    "\n",
    "# Function for doing class test/train/holdout split\n",
    "def split_fit_predict(data):\n",
    "  global gbm0,drf0,glm0,dl0\n",
    "  # Classic Test/Train split\n",
    "  r = data['Days'].runif()   # Random UNIForm numbers, one per row\n",
    "  train = data[  r  < 0.6]\n",
    "  test  = data[(0.6 <= r) & (r < 0.9)]\n",
    "  hold  = data[ 0.9 <= r ]\n",
    "  print \"Training data has\",train.ncol,\"columns and\",train.nrow,\"rows, test has\",test.nrow,\"rows, holdout has\",hold.nrow\n",
    "  \n",
    "  # Run GBM\n",
    "  s = time.time()\n",
    "  gbm0 = h2o.gbm(x           =train.drop(\"bikes\"),\n",
    "                 y           =train     [\"bikes\"],\n",
    "                 validation_x=test .drop(\"bikes\"),\n",
    "                 validation_y=test      [\"bikes\"],\n",
    "                 ntrees=500, # 500 works well\n",
    "                 max_depth=6,\n",
    "                 learn_rate=0.1)\n",
    "  gbm_elapsed = time.time() - s\n",
    "\n",
    "  # Run DRF\n",
    "  s = time.time()\n",
    "  drf0 = h2o.random_forest(x =train.drop(\"bikes\"),\n",
    "                y           =train     [\"bikes\"],\n",
    "                validation_x=test .drop(\"bikes\"),\n",
    "                validation_y=test      [\"bikes\"],\n",
    "                ntrees=250,\n",
    "                max_depth=30)\n",
    "  drf_elapsed = time.time() - s \n",
    "    \n",
    "    \n",
    "  # Run GLM, dropping WC1 because its mostly NAs\n",
    "  train_glm = train.drop(\"WC1\") if \"WC1\" in train.names else train\n",
    "  test_glm  = test .drop(\"WC1\") if \"WC1\" in test .names else test\n",
    "  s = time.time()\n",
    "  glm0 = h2o.glm(x           =train_glm.drop(\"bikes\"),\n",
    "                 y           =train_glm     [\"bikes\"],\n",
    "                 validation_x=test_glm .drop(\"bikes\"),\n",
    "                 validation_y=test_glm      [\"bikes\"],\n",
    "                 Lambda=[1e-5],\n",
    "                 family=\"poisson\")\n",
    "  glm_elapsed = time.time() - s\n",
    "  \n",
    "  # Run DL\n",
    "  s = time.time()\n",
    "  dl0 = h2o.deeplearning(x  =train.drop(\"bikes\"),\n",
    "                y           =train     [\"bikes\"],\n",
    "                validation_x=test .drop(\"bikes\"),\n",
    "                validation_y=test      [\"bikes\"],\n",
    "                hidden=[50,50,50,50],\n",
    "                epochs=50)\n",
    "  dl_elapsed = time.time() - s\n",
    "  \n",
    "  # ----------\n",
    "  # 4- Score on holdout set & report\n",
    "  train_r2_gbm = gbm0.model_performance(train).r2()\n",
    "  test_r2_gbm  = gbm0.model_performance(test ).r2()\n",
    "  hold_r2_gbm  = gbm0.model_performance(hold ).r2()\n",
    "#   print \"GBM R2 TRAIN=\",train_r2_gbm,\", R2 TEST=\",test_r2_gbm,\", R2 HOLDOUT=\",hold_r2_gbm\n",
    "  \n",
    "  train_r2_drf = drf0.model_performance(train).r2()\n",
    "  test_r2_drf  = drf0.model_performance(test ).r2()\n",
    "  hold_r2_drf  = drf0.model_performance(hold ).r2()\n",
    "#   print \"DRF R2 TRAIN=\",train_r2_drf,\", R2 TEST=\",test_r2_drf,\", R2 HOLDOUT=\",hold_r2_drf\n",
    "  \n",
    "  train_r2_glm = glm0.model_performance(train).r2()\n",
    "  test_r2_glm  = glm0.model_performance(test ).r2()\n",
    "  hold_r2_glm  = glm0.model_performance(hold ).r2()\n",
    "#   print \"GLM R2 TRAIN=\",train_r2_glm,\", R2 TEST=\",test_r2_glm,\", R2 HOLDOUT=\",hold_r2_glm\n",
    "\n",
    "  train_r2_dl = dl0.model_performance(train).r2()\n",
    "  test_r2_dl  = dl0.model_performance(test ).r2()\n",
    "  hold_r2_dl  = dl0.model_performance(hold ).r2()\n",
    "#   print \" DL R2 TRAIN=\",train_r2_dl,\", R2 TEST=\",test_r2_dl,\", R2 HOLDOUT=\",hold_r2_dl\n",
    "    \n",
    "  # make a pretty HTML table printout of the results\n",
    "\n",
    "  header = [\"Model\", \"R2 TRAIN\", \"R2 TEST\", \"R2 HOLDOUT\", \"Model Training Time (s)\"]\n",
    "  table  = [\n",
    "            [\"GBM\", train_r2_gbm, test_r2_gbm, hold_r2_gbm, round(gbm_elapsed,3)],\n",
    "            [\"DRF\", train_r2_drf, test_r2_drf, hold_r2_drf, round(drf_elapsed,3)],\n",
    "            [\"GLM\", train_r2_glm, test_r2_glm, hold_r2_glm, round(glm_elapsed,3)],\n",
    "            [\"DL \", train_r2_dl,  test_r2_dl,  hold_r2_dl , round(dl_elapsed,3) ],\n",
    "           ]\n",
    "  h2o.H2ODisplay(table,header)\n",
    "  # --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data (into test & train), fit some models and predict on the holdout data\n",
    "split_fit_predict(bpd)\n",
    "# Here we see an r^2 of 0.91 for GBM, and 0.71 for GLM.  This means given just\n",
    "# the station, the month, and the day-of-week we can predict 90% of the\n",
    "# variance of the bike-trip-starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# 5- Now lets add some weather\n",
    "# Load weather data\n",
    "wthr1 = h2o.import_file(path=[mylocate(\"bigdata/laptop/citibike-nyc/31081_New_York_City__Hourly_2013.csv\"),\n",
    "                               mylocate(\"bigdata/laptop/citibike-nyc/31081_New_York_City__Hourly_2014.csv\")])\n",
    "# Peek at the data\n",
    "wthr1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lots of columns in there!  Lets plan on converting to time-since-epoch to do\n",
    "# a 'join' with the bike data, plus gather weather info that might affect\n",
    "# cyclists - rain, snow, temperature.  Alas, drop the \"snow\" column since it's\n",
    "# all NA's.  Also add in dew point and humidity just in case.  Slice out just\n",
    "# the columns of interest and drop the rest.\n",
    "wthr2 = wthr1[[\"Year Local\",\"Month Local\",\"Day Local\",\"Hour Local\",\"Dew Point (C)\",\"Humidity Fraction\",\"Precipitation One Hour (mm)\",\"Temperature (C)\",\"Weather Code 1/ Description\"]]\n",
    "\n",
    "wthr2.set_name(wthr2.index(\"Precipitation One Hour (mm)\"), \"Rain (mm)\")\n",
    "wthr2.set_name(wthr2.index(\"Weather Code 1/ Description\"), \"WC1\")\n",
    "wthr2.describe()\n",
    "# Much better!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter down to the weather at Noon\n",
    "wthr3 = wthr2[ wthr2[\"Hour Local\"]==12 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets now get Days since the epoch... we'll convert year/month/day into Epoch\n",
    "# time, and then back to Epoch days.  Need zero-based month and days, but have\n",
    "# 1-based.\n",
    "wthr3[\"msec\"] = h2o.H2OFrame.mktime(year=wthr3[\"Year Local\"], month=wthr3[\"Month Local\"]-1, day=wthr3[\"Day Local\"]-1, hour=wthr3[\"Hour Local\"])\n",
    "secsPerDay=1000*60*60*24\n",
    "wthr3[\"Days\"] = (wthr3[\"msec\"]/secsPerDay).floor()\n",
    "wthr3.describe()\n",
    "# msec looks sane (numbers like 1.3e12 are in the correct range for msec since\n",
    "# 1970).  Epoch Days matches closely with the epoch day numbers from the\n",
    "# CitiBike dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets drop off the extra time columns to make a easy-to-handle dataset.\n",
    "wthr4 = wthr3.drop(\"Year Local\").drop(\"Month Local\").drop(\"Day Local\").drop(\"Hour Local\").drop(\"msec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Also, most rain numbers are missing - lets assume those are zero rain days\n",
    "rain = wthr4[\"Rain (mm)\"]\n",
    "rain[ rain.isna() ] = 0\n",
    "wthr4[\"Rain (mm)\"] = rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# 6 - Join the weather data-per-day to the bike-starts-per-day\n",
    "print \"Merge Daily Weather with Bikes-Per-Day\"\n",
    "bpd_with_weather = bpd.merge(wthr4,allLeft=True,allRite=False)\n",
    "bpd_with_weather.describe()\n",
    "bpd_with_weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7 - Test/Train split again, model build again, this time with weather\n",
    "split_fit_predict(bpd_with_weather)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
