{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutorial shows how H2O [Gradient Boosted Methods](https://en.wikipedia.org/wiki/Gradient_boosting) and [Random Forest](https://en.wikipedia.org/wiki/Random_forest) models can be used to do supervised classification and regression. This tutorial covers usage of H2O from Python. An R version of this tutorial will be available as well in a separate document. This file is available in plain R, R markdown, regular markdown, plain Python and iPython Notebook formats. More examples and explanations can be found in our [H2O GBM booklet](http://h2o.ai/resources/) and on our [H2O Github Repository](http://github.com/h2oai/h2o-3/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Task: Predicting forest cover type from cartographic variables only\n",
    "\n",
    "The actual forest cover type for a given observation (30 x 30 meter cell) was determined from the US Forest Service (USFS). We are using the UC Irvine Covertype dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O Python Module\n",
    "\n",
    "Load the H2O Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start H2O\n",
    "Start up a 1-node H2O cloud on your local machine, and allow it to use all CPU cores and up to 2GB of memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No instance found at ip and port: localhost:54321. Trying to start local jar...\n",
      "\n",
      "\n",
      "JVM stdout: c:\\users\\kevin\\appdata\\local\\temp\\tmpvlbjd1\\h2o_Kevin_started_from_python.out\n",
      "JVM stderr: c:\\users\\kevin\\appdata\\local\\temp\\tmp_0zyer\\h2o_Kevin_started_from_python.err\n",
      "Using ice_root: c:\\users\\kevin\\appdata\\local\\temp\\tmpxwtyyn\n",
      "\n",
      "\n",
      "Java Version: java version \"1.7.0_79\"\n",
      "Java(TM) SE Runtime Environment (build 1.7.0_79-b15)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: . Connection successful!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 seconds 821 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.7.0.3248</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total memory: </td>\n",
       "<td>1.78 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------\n",
       "H2O cluster uptime:         1 seconds 821 milliseconds\n",
       "H2O cluster version:        3.7.0.3248\n",
       "H2O cluster name:           H2O_started_from_python\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster total memory:   1.78 GB\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster healthy:        True\n",
       "H2O Connection ip:          127.0.0.1\n",
       "H2O Connection port:        54321\n",
       "--------------------------  --------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(max_mem_size_GB = 2)            #uses all cores by default\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the h2o package itself, we can use Python's builtin help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package h2o:\n",
      "\n",
      "NAME\n",
      "    h2o\n",
      "\n",
      "FILE\n",
      "    d:\\anaconda\\lib\\site-packages\\h2o\\__init__.py\n",
      "\n",
      "DESCRIPTION\n",
      "    The H2O Python Module\n",
      "    =====================\n",
      "    \n",
      "    This module provides access to the H2O JVM, as well as its extensions, objects,\n",
      "    machine-learning algorithms, and modeling support capabilities, such as basic\n",
      "    munging and feature generation.\n",
      "    \n",
      "    The H2O JVM uses a web server so that all communication occurs on a socket (specified\n",
      "    by an IP address and a port) via a series of REST calls (see connection.py for the REST\n",
      "    layer implementation and details). There is a single active connection to the H2O JVM at\n",
      "    any time, and this handle is stashed out of sight in a singleton instance of\n",
      "    :class:`H2OConnection` (this is the global  :envvar:`__H2OConn__`). In other words,\n",
      "    this package does not rely on Jython, and there is no direct manipulation of the JVM.\n",
      "    \n",
      "    The H2O python module is not intended as a replacement for other popular machine learning\n",
      "    frameworks such as scikit-learn, pylearn2, and their ilk, but is intended to bring H2O to\n",
      "    a wider audience of data and machine learning devotees who work exclusively with Python.\n",
      "    \n",
      "    H2O from Python is a tool for rapidly turning over models, doing data munging, and\n",
      "    building applications in a fast, scalable environment without any of the mental anguish\n",
      "    about parallelism and distribution of work.\n",
      "    \n",
      "    What is H2O?\n",
      "    ------------\n",
      "    \n",
      "    H2O is a Java-based software for data modeling and general computing. There are many\n",
      "    different perceptions of the H2O software, but the primary purpose of H2O is as a\n",
      "    distributed (many machines), parallel (many CPUs), in memory (several hundred GBs Xmx)\n",
      "    processing engine.\n",
      "    \n",
      "    There are two levels of parallelism:\n",
      "    \n",
      "        * within node\n",
      "        * across (or between) nodes\n",
      "    \n",
      "    The goal, remember, is to easily add more processors to a given problem in order to\n",
      "    produce a solution faster. The conceptual paradigm MapReduce (also known as\n",
      "    \"divide and conquer and combine\"), along with a good concurrent application structure,\n",
      "    (c.f. jsr166y and NonBlockingHashMap) enable this type of scaling in H2O -- we're really\n",
      "    cooking with gas now!\n",
      "    \n",
      "    For application developers and data scientists, the gritty details of thread-safety,\n",
      "    algorithm parallelism, and node coherence on a network are concealed by simple-to-use REST\n",
      "    calls that are all documented here. In addition, H2O is an open-source project under the\n",
      "    Apache v2 licence. All of the source code is on\n",
      "    `github <https://github.com/h2oai/h2o-dev>`_, there is an active\n",
      "    `google group mailing list <https://groups.google.com/forum/#!forum/h2ostream>`_, our\n",
      "    `nightly tests <http://test.0xdata.com/>`_ are open for perusal, and our `JIRA ticketing\n",
      "    system <http://jira.0xdata.com>`_ is also open for public use. Last, but not least, we\n",
      "    regularly engage the machine learning community all over the nation with a very busy\n",
      "    `meetup schedule <http://h2o.ai/events/>`_ (so if you're not in The Valley, no sweat,\n",
      "    we're probably coming to your area soon!), and finally, we host our very own `H2O World\n",
      "    conference <http://h2o.ai/h2o-world/>`_. We also sometimes host hack-a-thons at our\n",
      "    campus in Mountain View, CA. Needless to say, H2O provides a lot of support for\n",
      "    application developers.\n",
      "    \n",
      "    In order to make the most out of H2O, there are some key conceptual pieces that are important\n",
      "    to know before getting started. Mainly, it's helpful to know about the different types of\n",
      "    objects that live in H2O and what the rules of engagement are in the context of the REST\n",
      "    API (which is what any non-JVM interface is all about).\n",
      "    \n",
      "    Let's get started!\n",
      "    \n",
      "    The H2O Object System\n",
      "    +++++++++++++++++++++\n",
      "    \n",
      "    H2O uses a distributed key-value store (the \"DKV\") that contains pointers to the\n",
      "    various objects of the H2O ecosystem. The DKV is a kind of biosphere in that it\n",
      "    encapsulates all shared objects; however, it may not encapsulate all objects. Some shared\n",
      "    objects are mutable by the client; some shared objects are read-only by the client, but are\n",
      "    mutable by H2O (e.g. a model being constructed will change over time); and actions by the\n",
      "    client may have side-effects on other clients (multi-tenancy is not a supported model of\n",
      "    use, but it is possible for multiple clients to attach to a single H2O cloud).\n",
      "    \n",
      "    Briefly, these objects are:\n",
      "    \n",
      "         * :mod:`Key`:    A key is an entry in the DKV that maps to an object in H2O.\n",
      "    \n",
      "         * :mod:`Frame`:  A Frame is a collection of Vec objects. It is a 2D array of elements.\n",
      "    \n",
      "         * :mod:`Vec`:    A Vec is a collection of Chunk objects. It is a 1D array of elements.\n",
      "    \n",
      "         * :mod:`Chunk`:  A Chunk holds a fraction of the BigData. It is a 1D array of elements.\n",
      "    \n",
      "         * :mod:`ModelMetrics`:   A collection of metrics for a given category of model.\n",
      "    \n",
      "         * :mod:`Model`:  A model is an immutable object having `predict` and `metrics` methods.\n",
      "    \n",
      "         * :mod:`Job`:    A Job is a non-blocking task that performs a finite amount of work.\n",
      "    \n",
      "    Many of these objects have no meaning to a Python end-user, but to make sense of\n",
      "    the objects available in this module it is helpful to understand how these objects map to\n",
      "    objects in the JVM. After all, this module is an interface that allows the\n",
      "    manipulation of a distributed system.\n",
      "    \n",
      "    \n",
      "    Objects In This Module\n",
      "    ----------------------\n",
      "    \n",
      "    The objects that are of primary concern to the python user are (in order of importance)\n",
      "    - IDs/Keys\n",
      "    - Frames\n",
      "    - Models\n",
      "    - ModelMetrics\n",
      "    - Jobs (to a lesser extent)\n",
      "    Each of these objects are described in greater detail in this documentation,\n",
      "    but a few brief notes are provided here.\n",
      "    \n",
      "    \n",
      "    H2OFrame\n",
      "    ++++++++\n",
      "    \n",
      "    An H2OFrame is a 2D array of uniformly-typed columns. Data in H2O is compressed (often\n",
      "    achieving 2-4x better compression than gzip on disk) and is held in the JVM heap (i.e.\n",
      "    data is \"in memory\"), and *not* in the python process local memory. The H2OFrame is an\n",
      "    iterable (supporting list comprehensions). All an H2OFrame object is, therefore, is a\n",
      "    wrapper on a list that supports various types of operations that may or may not be lazy.\n",
      "    Here's an example showing how a list comprehension is combined with lazy expressions to\n",
      "    compute the column means for all columns in the H2OFrame::\n",
      "    \n",
      "      >>> df = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate data\n",
      "      >>>\n",
      "      >>> colmeans = df.mean()                                        # compute column means\n",
      "      >>>\n",
      "      >>> colmeans                                                    # print the results\n",
      "      [5.843333333333335, 3.0540000000000007, 3.7586666666666693, 1.1986666666666672]\n",
      "    \n",
      "    Lazy expressions will be discussed briefly in the coming sections, as they are not\n",
      "    necessarily going to be integral to the practicing data scientist. However, their primary\n",
      "    purpose is to cut down on the chatter between the client (a.k.a the python interface) and\n",
      "    H2O. Lazy expressions are `Katamari'd <http://www.urbandictionary.com/define.php?term=Katamari>`_\n",
      "    together and only ever evaluated when some piece of output is requested (e.g. print-to-screen).\n",
      "    \n",
      "    The set of operations on an H2OFrame is described in a dedicated chapter, but\n",
      "    in general, this set of operations closely resembles those that may be\n",
      "    performed on an R data.frame. This includes all types of slicing (with complex\n",
      "    conditionals), broadcasting operations, and a slew of math operations for transforming and\n",
      "    mutating a Frame -- all the while the actual Big Data is sitting in the H2O cloud. The semantics\n",
      "    for modifying a Frame closely resemble R's copy-on-modify semantics, except when it comes\n",
      "    to mutating a Frame in place. For example, it's possible to assign all occurrences of the\n",
      "    number `0` in a column to missing (or `NA` in R parlance) as demonstrated in the following\n",
      "    snippet::\n",
      "    \n",
      "    \n",
      "      >>> df = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate data\n",
      "      >>>\n",
      "      >>> vol = df['VOL']                                              # select the VOL column\n",
      "      >>>\n",
      "      >>> vol[vol == 0] = None                                         # 0 VOL means 'missing'\n",
      "    \n",
      "    After this operation, `vol` has been permanently mutated in place (it is not a copy!).\n",
      "    \n",
      "    ExprNode\n",
      "    ++++++++\n",
      "    In the guts of this module is the Expr class, which defines objects holding\n",
      "    the cumulative, unevaluated expressions that may become H2OFrame objects.\n",
      "    For example:\n",
      "    \n",
      "      >>> fr = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate data\n",
      "      >>>\n",
      "      >>> a = fr + 3.14159                                             # \"a\" is now an Expr\n",
      "      >>>\n",
      "      >>> type(a)                                                      # <class 'h2o.expr.Expr'>\n",
      "    \n",
      "    These objects are not as important to distinguish at the user level, and all operations\n",
      "    can be performed with the mental model of operating on 2D frames (i.e. everything is an\n",
      "    H2OFrame).\n",
      "    \n",
      "    In the previous snippet, `a` has not yet triggered any big data evaluation and is, in\n",
      "    fact, a pending computation. Once `a` is evaluated, it stays evaluated. Additionally,\n",
      "    all dependent subparts composing `a` are also evaluated.\n",
      "    \n",
      "    This module relies on reference counting of python objects to dispose of\n",
      "    out-of-scope objects. The Expr class destroys objects and their big data\n",
      "    counterparts in the H2O cloud using a remove call:\n",
      "    \n",
      "      >>> fr = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate data\n",
      "      >>>\n",
      "      >>> h2o.remove(fr)                                               # remove prostate data\n",
      "      >>> fr                                                           # attempting to use fr results in a ValueError\n",
      "    \n",
      "    Notice that attempting to use the object after a remove call has been issued will\n",
      "    result in a ValueError. Therefore, any working references may not be cleaned up,\n",
      "    but they will no longer be functional. Deleting an unevaluated expression will not\n",
      "    delete all subparts.\n",
      "    \n",
      "    Models\n",
      "    ++++++\n",
      "    \n",
      "    The model-building experience with this module is unique, especially for those coming\n",
      "    from a background in scikit-learn. Instead of using objects to build the model,\n",
      "    builder functions are provided in the top-level module, and the result of a call\n",
      "    is a model object belonging to one of the following categories:\n",
      "    \n",
      "        * Regression\n",
      "        * Binomial\n",
      "        * Multinomial\n",
      "        * Clustering\n",
      "        * Autoencoder\n",
      "    \n",
      "    To better demonstrate this concept, refer to the following example:\n",
      "    \n",
      "      >>> fr = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate data\n",
      "      >>>\n",
      "      >>> fr[1] = fr[1].asfactor()                                     # make 2nd column a factor\n",
      "      >>>\n",
      "      >>> m = h2o.glm(x=fr[3:], y=fr[2])                               # build a glm with a method call\n",
      "      >>>\n",
      "      >>> m.__class__                                                  # <h2o.model.binomial.H2OBinomialModel object at 0x104659cd0>\n",
      "      >>>\n",
      "      >>> m.show()                                                     # print the model details\n",
      "      >>>\n",
      "      >>> m.summary()                                                  # print a model summary\n",
      "    \n",
      "    As you can see in the example, the result of the GLM call is a binomial model. This example also showcases\n",
      "    an important feature-munging step needed for GLM to perform a classification task rather than a\n",
      "    regression task. Namely, the second column is initially read as a numeric column,\n",
      "    but it must be changed to a factor by way of the operation `asfactor`. Let's take a look\n",
      "    at this more deeply:\n",
      "    \n",
      "      >>> fr = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate data\n",
      "      >>>\n",
      "      >>> fr[1].isfactor()                                             # produces False\n",
      "      >>>\n",
      "      >>> m = h2o.gbm(x=fr[2:],y=fr[1])                                # build the gbm\n",
      "      >>>\n",
      "      >>> m.__class__                                                  # <h2o.model.regression.H2ORegressionModel object at 0x104d07590>\n",
      "      >>>\n",
      "      >>> fr[1] = fr[1].asfactor()                                     # cast the 2nd column to a factor column\n",
      "      >>>\n",
      "      >>> fr[1].isfactor()                                             # produces True\n",
      "      >>>\n",
      "      >>> m = h2o.gbm(x=fr[2:],y=fr[1])                                # build the gbm\n",
      "      >>>\n",
      "      >>> m.__class__                                                  # <h2o.model.binomial.H2OBinomialModel object at 0x104d18f50>\n",
      "    \n",
      "    The above example shows how to properly deal with numeric columns you would like to use in a\n",
      "    classification setting. Additionally, H2O can perform on-the-fly scoring of validation\n",
      "    data and provide a host of metrics on the validation and training data. Here's an example\n",
      "    of this functionality, where we additionally split the data set into three pieces for training,\n",
      "    validation, and finally testing:\n",
      "    \n",
      "      >>> fr = h2o.import_file(path=\"smalldata/logreg/prostate.csv\")  # import prostate\n",
      "      >>>\n",
      "      >>> fr[1] = fr[1].asfactor()                                     # cast to factor\n",
      "      >>>\n",
      "      >>> r = fr[0].runif()                                            # Random UNIform numbers, one per row\n",
      "      >>>\n",
      "      >>> train = fr[ r < 0.6 ]                                        # 60% for training data\n",
      "      >>>\n",
      "      >>> valid = fr[ (0.6 <= r) & (r < 0.9) ]                         # 30% for validation\n",
      "      >>>\n",
      "      >>> test  = fr[ 0.9 <= r ]                                       # 10% for testing\n",
      "      >>>\n",
      "      >>> m = h2o.deeplearning(x=train[2:],y=train[1],validation_x=valid[2:],validation_y=valid[1])  # build a deeplearning with a validation set (yes it's this simple)\n",
      "      >>>\n",
      "      >>> m                                                            # display the model summary by default (can also call m.show())\n",
      "      >>>\n",
      "      >>> m.show()                                                     # equivalent to the above\n",
      "      >>>\n",
      "      >>> m.model_performance()                                        # show the performance on the training data, (can also be m.performance(train=True)\n",
      "      >>>\n",
      "      >>> m.model_performance(valid=True)                              # show the performance on the validation data\n",
      "      >>>\n",
      "      >>> m.model_performance(test_data=test)                          # score and compute new metrics on the test data!\n",
      "    \n",
      "    Expanding on this example, there are a number of ways of querying a model for its attributes.\n",
      "    Here are some examples of how to do just that:\n",
      "    \n",
      "      >>> m.mse()           # MSE on the training data\n",
      "      >>>\n",
      "      >>> m.mse(valid=True) # MSE on the validation data\n",
      "      >>>\n",
      "      >>> m.r2()            # R^2 on the training data\n",
      "      >>>\n",
      "      >>> m.r2(valid=True)  # R^2 on the validation data\n",
      "      >>>\n",
      "      >>> m.confusion_matrix()  # confusion matrix for max F1\n",
      "      >>>\n",
      "      >>> m.confusion_matrix(\"tpr\") # confusion matrix for max true positive rate\n",
      "      >>>\n",
      "      >>> m.confusion_matrix(\"max_per_class_error\")   # etc.\n",
      "    \n",
      "    All of our models support various accessor methods such as these. The following section will\n",
      "    discuss model metrics in greater detail.\n",
      "    \n",
      "    On a final note, each of H2O's algorithms handles missing (colloquially: \"missing\" or \"NA\")\n",
      "    and categorical data automatically differently, depending on the algorithm. You can find\n",
      "    out more about each of the individual differences at the following link: http://docs2.h2o.ai/datascience/top.html\n",
      "    \n",
      "    Metrics\n",
      "    +++++++\n",
      "    \n",
      "    H2O models exhibit a wide array of metrics for each of the model categories:\n",
      "    - Clustering\n",
      "    - Binomial\n",
      "    - Multinomial\n",
      "    - Regression\n",
      "    - AutoEncoder\n",
      "    In turn, each of these categories is associated with a corresponding H2OModelMetrics class.\n",
      "    \n",
      "    All algorithm calls return at least one type of metrics: the training set metrics. When building\n",
      "    a model in H2O, you can optionally provide a validation set for on-the-fly evaluation of\n",
      "    holdout data. If the validation set is provided, then two types of metrics are returned:\n",
      "    the training set metrics and the validation set metrics.\n",
      "    \n",
      "    In addition to the metrics that can be retrieved at model-build time, there is a\n",
      "    possible third type of metrics available post-build for the final holdout test set that\n",
      "    contains data that does not appear in either the training or validation sets: the\n",
      "    test set metrics. While the returned object is an H2OModelMetrics rather than an H2O model,\n",
      "    it can be queried in the same exact way. Here's an example:\n",
      "    \n",
      "      >>> fr = h2o.import_file(path=\"smalldata/iris/iris_wheader.csv\")   # import iris\n",
      "      >>>\n",
      "      >>> r = fr[0].runif()                       # generate a random vector for splitting\n",
      "      >>>\n",
      "      >>> train = fr[ r < 0.6 ]                   # split out 60% for training\n",
      "      >>>\n",
      "      >>> valid = fr[ 0.6 <= r & r < 0.9 ]        # split out 30% for validation\n",
      "      >>>\n",
      "      >>> test = fr[ 0.9 <= r ]                   # split out 10% for testing\n",
      "      >>>\n",
      "      >>> my_model = h2o.glm(x=train[1:], y=train[0], validation_x=valid[1:], validation_y=valid[0])  # build a GLM\n",
      "      >>>\n",
      "      >>> my_model.coef()                         # print the GLM coefficients, can also perform my_model.coef_norm() to get the normalized coefficients\n",
      "      >>>\n",
      "      >>> my_model.null_deviance()                # get the null deviance from the training set metrics\n",
      "      >>>\n",
      "      >>> my_model.residual_deviance()            # get the residual deviance from the training set metrics\n",
      "      >>>\n",
      "      >>> my_model.null_deviance(valid=True)      # get the null deviance from the validation set metrics (similar for residual deviance)\n",
      "      >>>\n",
      "      >>> # now generate a new metrics object for the test hold-out data:\n",
      "      >>>\n",
      "      >>> my_metrics = my_model.model_performance(test_data=test) # create the new test set metrics\n",
      "      >>>\n",
      "      >>> my_metrics.null_degrees_of_freedom()    # returns the test null dof\n",
      "      >>>\n",
      "      >>> my_metrics.residual_deviance()          # returns the test res. deviance\n",
      "      >>>\n",
      "      >>> my_metrics.aic()                        # returns the test aic\n",
      "    \n",
      "    As you can see, the new model metrics object generated by calling `model_performance` on the\n",
      "    model object supports all of the metric accessor methods as a model. For a complete list of\n",
      "    the available metrics for various model categories, please refer to the \"Metrics in H2O\" section\n",
      "    of this document.\n",
      "    \n",
      "    Example of H2O on Hadoop\n",
      "    ------------------------\n",
      "    \n",
      "    Here is a brief example of H2O on Hadoop:\n",
      "    \n",
      "    .. code-block:: python\n",
      "    \n",
      "      import h2o\n",
      "      h2o.init(ip=\"192.168.1.10\", port=54321)\n",
      "      --------------------------  ------------------------------------\n",
      "      H2O cluster uptime:         2 minutes 1 seconds 966 milliseconds\n",
      "      H2O cluster version:        0.1.27.1064\n",
      "      H2O cluster name:           H2O_96762\n",
      "      H2O cluster total nodes:    4\n",
      "      H2O cluster total memory:   38.34 GB\n",
      "      H2O cluster total cores:    16\n",
      "      H2O cluster allowed cores:  80\n",
      "      H2O cluster healthy:        True\n",
      "      --------------------------  ------------------------------------\n",
      "      pathDataTrain = [\"hdfs://192.168.1.10/user/data/data_train.csv\"]\n",
      "      pathDataTest = [\"hdfs://192.168.1.10/user/data/data_test.csv\"]\n",
      "      trainFrame = h2o.import_file(path=pathDataTrain)\n",
      "      testFrame = h2o.import_file(path=pathDataTest)\n",
      "    \n",
      "      #Parse Progress: [##################################################] 100%\n",
      "      #Imported [hdfs://192.168.1.10/user/data/data_train.csv'] into cluster with 60000 rows and 500 cols\n",
      "    \n",
      "      #Parse Progress: [##################################################] 100%\n",
      "      #Imported ['hdfs://192.168.1.10/user/data/data_test.csv'] into cluster with 10000 rows and 500 cols\n",
      "    \n",
      "      trainFrame[499]._name = \"label\"\n",
      "      testFrame[499]._name = \"label\"\n",
      "    \n",
      "      model = h2o.gbm(x=trainFrame.drop(\"label\"),\n",
      "                  y=trainFrame[\"label\"],\n",
      "                  validation_x=testFrame.drop(\"label\"),\n",
      "                  validation_y=testFrame[\"label\"],\n",
      "                  ntrees=100,\n",
      "                  max_depth=10\n",
      "                  )\n",
      "    \n",
      "      #gbm Model Build Progress: [##################################################] 100%\n",
      "    \n",
      "      predictFrame = model.predict(testFrame)\n",
      "      model.model_performance(testFrame)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    assembly\n",
      "    astfun\n",
      "    connection\n",
      "    cross_validation\n",
      "    demo\n",
      "    estimators (package)\n",
      "    expr\n",
      "    frame\n",
      "    grid (package)\n",
      "    group_by\n",
      "    h2o\n",
      "    h2o_logging\n",
      "    h2o_model_builder\n",
      "    job\n",
      "    model (package)\n",
      "    transforms (package)\n",
      "    two_dim_table\n",
      "\n",
      "SUBMODULES\n",
      "    autoencoder\n",
      "    binomial\n",
      "    clustering\n",
      "    confusion_matrix\n",
      "    dim_reduction\n",
      "    estimator_base\n",
      "    metrics_base\n",
      "    model_base\n",
      "    model_future\n",
      "    multinomial\n",
      "    regression\n",
      "\n",
      "CLASSES\n",
      "    __builtin__.object\n",
      "        h2o.connection.H2OConnection\n",
      "        h2o.frame.H2OFrame\n",
      "        h2o.two_dim_table.H2OTwoDimTable\n",
      "    h2o.group_by.GroupBy\n",
      "    \n",
      "    class GroupBy\n",
      "     |  A class that represents the group by operation on an H2OFrame.\n",
      "     |  \n",
      "     |  Sample usage:\n",
      "     |  \n",
      "     |         >>> my_frame = ...  # some existing H2OFrame\n",
      "     |         >>> grouped = my_frame.group_by(by=[\"C1\",\"C2\"])\n",
      "     |         >>> grouped.sum(col=\"X1\",na=\"all\").mean(col=\"X5\",na=\"all\").max()\n",
      "     |         >>> grouped.get_frame\n",
      "     |  \n",
      "     |  Any number of aggregations may be chained together in this manner.\n",
      "     |  \n",
      "     |  If no arguments are given to the aggregation (e.g. \"max\" in the above example),\n",
      "     |  then it is assumed that the aggregation should apply to all columns but the\n",
      "     |  group by columns.\n",
      "     |  \n",
      "     |  The na parameter is one of [\"all\",\"ignore\",\"rm\"].\n",
      "     |      \"all\"    - include NAs\n",
      "     |      \"rm\"     - exclude NAs\n",
      "     |  \n",
      "     |  Variance (var) and standard deviation (sd) are the sample (not population) statistics.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, fr, by)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |  \n",
      "     |  count(self, na='all')\n",
      "     |  \n",
      "     |  get_frame(self)\n",
      "     |      :return: the result of the group by\n",
      "     |  \n",
      "     |  max(self, col=None, na='all')\n",
      "     |  \n",
      "     |  mean(self, col=None, na='all')\n",
      "     |  \n",
      "     |  min(self, col=None, na='all')\n",
      "     |  \n",
      "     |  mode(self, col=None, na='all')\n",
      "     |  \n",
      "     |  sd(self, col=None, na='all')\n",
      "     |  \n",
      "     |  ss(self, col=None, na='all')\n",
      "     |      # def first(self,col=None,na=\"all\"): return self._add_agg(\"first\",col,na)\n",
      "     |      # def last( self,col=None,na=\"all\"): return self._add_agg(\"last\",col,na)\n",
      "     |  \n",
      "     |  sum(self, col=None, na='all')\n",
      "     |  \n",
      "     |  var(self, col=None, na='all')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  frame\n",
      "     |      :return: the result of the group by\n",
      "    \n",
      "    class H2OConnection(__builtin__.object)\n",
      "     |  H2OConnection is a class that represents a connection to the H2O cluster.\n",
      "     |  It is specified by an IP address and a port number.\n",
      "     |  \n",
      "     |  Objects of type H2OConnection are not instantiated directly!\n",
      "     |  \n",
      "     |  This class contains static methods for performing the common REST methods\n",
      "     |  GET, POST, and DELETE.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, ip='localhost', port=54321, size=1, start_h2o=False, enable_assertions=False, license=None, max_mem_size_GB=None, min_mem_size_GB=None, ice_root=None, strict_version_check=True)\n",
      "     |      Instantiate the package handle to the H2O cluster.\n",
      "     |      :param ip: An IP address, default is \"localhost\"\n",
      "     |      :param port: A port, default is 54321\n",
      "     |      :param size: THe expected number of h2o instances (ignored if start_h2o is True)\n",
      "     |      :param start_h2o: A boolean dictating whether this module should start the H2O jvm. An attempt is made anyways if _connect fails.\n",
      "     |      :param enable_assertions: If start_h2o, pass `-ea` as a VM option.s\n",
      "     |      :param license: If not None, is a path to a license file.\n",
      "     |      :param max_mem_size_GB: Maximum heap size (jvm option Xmx) in gigabytes.\n",
      "     |      :param min_mem_size_GB: Minimum heap size (jvm option Xms) in gigabytes.\n",
      "     |      :param ice_root: A temporary directory (default location is determined by tempfile.mkdtemp()) to hold H2O log files.\n",
      "     |      :return: None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  check_conn()\n",
      "     |  \n",
      "     |  cluster_is_up(conn)\n",
      "     |      Determine if an H2O cluster is up or not\n",
      "     |      :param conn: An H2OConnection object containing the IP address and port of the server running H2O.\n",
      "     |      :return: TRUE if the cluster is up; FALSE otherwise\n",
      "     |  \n",
      "     |  current_connection()\n",
      "     |  \n",
      "     |  delete(url_suffix, **kwargs)\n",
      "     |  \n",
      "     |  get(url_suffix, **kwargs)\n",
      "     |  \n",
      "     |  get_json(url_suffix, **kwargs)\n",
      "     |  \n",
      "     |  ip()\n",
      "     |  \n",
      "     |  make_url(url_suffix, **kwargs)\n",
      "     |  \n",
      "     |  port()\n",
      "     |  \n",
      "     |  post(url_suffix, file_upload_info=None, **kwargs)\n",
      "     |  \n",
      "     |  post_json(url_suffix, file_upload_info=None, **kwargs)\n",
      "     |  \n",
      "     |  rest_ctr()\n",
      "     |  \n",
      "     |  rest_version()\n",
      "     |  \n",
      "     |  session_id()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class H2OFrame(__builtin__.object)\n",
      "     |  # TODO: Automatically convert column names into Frame properties!\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__(self)\n",
      "     |      # unops\n",
      "     |  \n",
      "     |  __add__(self, i)\n",
      "     |      # ops\n",
      "     |  \n",
      "     |  __and__(self, i)\n",
      "     |  \n",
      "     |  __contains__(self, i)\n",
      "     |  \n",
      "     |  __div__(self, i)\n",
      "     |  \n",
      "     |  __eq__(self, i)\n",
      "     |  \n",
      "     |  __float__(self)\n",
      "     |  \n",
      "     |  __floordiv__(self, i)\n",
      "     |  \n",
      "     |  __ge__(self, i)\n",
      "     |  \n",
      "     |  __getitem__(self, item)\n",
      "     |      Frame slicing. Supports R-like row and column slicing.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        item : tuple, list, string, int\n",
      "     |           If a tuple, then this indicates both row and column selection. The tuple\n",
      "     |           must be exactly length 2.\n",
      "     |           If a list, then this indicates column selection.\n",
      "     |           If a int, the this indicates a single column to be retrieved at the index.\n",
      "     |           If a string, then slice on the column with this name.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        An instance of H2OFrame.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |        fr[2]              # All rows, column 2\n",
      "     |        fr[-2]             # All rows, 2nd column from end\n",
      "     |        fr[:,-1]           # All rows, last column\n",
      "     |        fr[0:5,:]          # first 5 rows, all columns\n",
      "     |        fr[fr[0] > 1, :]   # all rows greater than 1 in the first column, all columns\n",
      "     |        fr[[1,5,6]]        # columns 1, 5, and 6\n",
      "     |        fr[0:50, [1,2,3]]  # first 50 rows, columns 1,2, and 3\n",
      "     |  \n",
      "     |  __gt__(self, i)\n",
      "     |  \n",
      "     |  __init__(self, python_object=None)\n",
      "     |  \n",
      "     |  __int__(self)\n",
      "     |  \n",
      "     |  __invert__(self)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __le__(self, i)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __lt__(self, i)\n",
      "     |  \n",
      "     |  __mod__(self, i)\n",
      "     |  \n",
      "     |  __mul__(self, i)\n",
      "     |  \n",
      "     |  __ne__(self, i)\n",
      "     |  \n",
      "     |  __or__(self, i)\n",
      "     |  \n",
      "     |  __pow__(self, i)\n",
      "     |  \n",
      "     |  __radd__(self, i)\n",
      "     |  \n",
      "     |  __rand__(self, i)\n",
      "     |  \n",
      "     |  __rdiv__(self, i)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |  \n",
      "     |  __rfloordiv__(self, i)\n",
      "     |  \n",
      "     |  __rmod__(self, i)\n",
      "     |      # rops\n",
      "     |  \n",
      "     |  __rmul__(self, i)\n",
      "     |  \n",
      "     |  __ror__(self, i)\n",
      "     |  \n",
      "     |  __rpow__(self, i)\n",
      "     |  \n",
      "     |  __rsub__(self, i)\n",
      "     |  \n",
      "     |  __setitem__(self, b, c)\n",
      "     |      Replace or update column(s) in an H2OFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        b : int, str\n",
      "     |          A 0-based index or a column name.\n",
      "     |        c :\n",
      "     |          The value replacing 'b'\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Returns this H2OFrame.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |  \n",
      "     |  __sub__(self, i)\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |  \n",
      "     |  acos(self)\n",
      "     |  \n",
      "     |  acosh(self)\n",
      "     |  \n",
      "     |  all(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if every element is True or NA in the column.\n",
      "     |  \n",
      "     |  any(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if any element is True or NA in the column.\n",
      "     |  \n",
      "     |  any_na_rm(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if any element is True in the column.\n",
      "     |  \n",
      "     |  anyfactor(self)\n",
      "     |      Test if H2OFrame has any factor columns.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if there are any categorical columns; False otherwise.\n",
      "     |  \n",
      "     |  apply(self, fun=None, axis=0)\n",
      "     |      Apply a lambda expression to an H2OFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        fun: lambda\n",
      "     |          A lambda expression to be applied per row or per column\n",
      "     |      axis: int\n",
      "     |        0: apply to each column; 1: apply to each row\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  as_data_frame(self, use_pandas=False)\n",
      "     |      Obtain the dataset as a python-local object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        use_pandas : bool, default=False\n",
      "     |          A flag specifying whether or not to return a pandas DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A local python object (a list of lists of strings, each list is a row, if\n",
      "     |        use_pandas=False, otherwise a pandas DataFrame) containing this H2OFrame instance's\n",
      "     |        data.\n",
      "     |  \n",
      "     |  as_date(self, format)\n",
      "     |      Return the column with all elements converted to millis since the epoch.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        format : str\n",
      "     |          A datetime format string (e.g. \"YYYY-mm-dd\")\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        An H2OFrame instance.\n",
      "     |  \n",
      "     |  ascharacter(self)\n",
      "     |      All columns converted to String columns\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  asfactor(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2Oframe of one column converted to a factor.\n",
      "     |  \n",
      "     |  asin(self)\n",
      "     |  \n",
      "     |  asinh(self)\n",
      "     |  \n",
      "     |  asnumeric(self)\n",
      "     |      All factor columns converted to numeric.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  atan(self)\n",
      "     |  \n",
      "     |  atanh(self)\n",
      "     |  \n",
      "     |  cbind(self, data)\n",
      "     |      Append data to this H2OFrame column-wise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : H2OFrame\n",
      "     |        H2OFrame to be column bound to the right of this H2OFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame of the combined datasets.\n",
      "     |  \n",
      "     |  ceil(self)\n",
      "     |  \n",
      "     |  cos(self)\n",
      "     |  \n",
      "     |  cosh(self)\n",
      "     |  \n",
      "     |  cospi(self)\n",
      "     |  \n",
      "     |  countmatches(self, pattern)\n",
      "     |      For each string in the column, count the occurrences of pattern.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pattern : str\n",
      "     |        The pattern to count matches on in each string.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A single-column H2OFrame containing the counts for the per-row occurrences of\n",
      "     |        pattern in the input column.\n",
      "     |  \n",
      "     |  cummax(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The cumulative max over the column.\n",
      "     |  \n",
      "     |  cummin(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The cumulative min over the column.\n",
      "     |  \n",
      "     |  cumprod(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The cumulative product over the column.\n",
      "     |  \n",
      "     |  cumsum(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The cumulative sum over the column.\n",
      "     |  \n",
      "     |  cut(self, breaks, labels=None, include_lowest=False, right=True, dig_lab=3)\n",
      "     |      Cut a numeric vector into factor \"buckets\". Similar to R's cut method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      breaks : list\n",
      "     |        The cut points in the numeric vector (must span the range of the col.)\n",
      "     |      labels: list\n",
      "     |        Factor labels, defaults to set notation of intervals defined by breaks.\n",
      "     |      include_lowest : bool\n",
      "     |        By default,  cuts are defined as (lo,hi]. If True, get [lo,hi].\n",
      "     |      right : bool\n",
      "     |        Include the high value: (lo,hi]. If False, get (lo,hi).\n",
      "     |      dig_lab: int\n",
      "     |        Number of digits following the decimal point to consider.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Single-column H2OFrame of categorical data.\n",
      "     |  \n",
      "     |  day(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Day column from a msec-since-Epoch column\n",
      "     |  \n",
      "     |  dayOfWeek(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Day-of-Week column from a msec-since-Epoch column\n",
      "     |  \n",
      "     |  ddply(self, cols, fun)\n",
      "     |      Unimplemented\n",
      "     |  \n",
      "     |  describe(self)\n",
      "     |      Generate an in-depth description of this H2OFrame. Everything in summary(), plus\n",
      "     |      the data layout.\n",
      "     |  \n",
      "     |  digamma(self)\n",
      "     |  \n",
      "     |  drop(self, i)\n",
      "     |      Drop a column from the current H2OFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        i : str, int\n",
      "     |          The column to be dropped\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame with the column at index i dropped. Returns a new H2OFrame.\n",
      "     |  \n",
      "     |  exp(self)\n",
      "     |  \n",
      "     |  expm1(self)\n",
      "     |  \n",
      "     |  filter_na_cols(self, frac=0.2)\n",
      "     |      Filter columns with proportion of NAs >= frac.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      frac : float\n",
      "     |        Fraction of NAs in the column.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list of column indices\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |  \n",
      "     |  floor(self)\n",
      "     |  \n",
      "     |  gamma(self)\n",
      "     |  \n",
      "     |  group_by(self, by)\n",
      "     |      Returns a new GroupBy object using this frame and the desired grouping columns.\n",
      "     |         The returned groups are sorted by the natural group-by column sort.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : list\n",
      "     |          The columns to group on.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A new GroupBy object.\n",
      "     |  \n",
      "     |  gsub(self, pattern, replacement, ignore_case=False)\n",
      "     |      Globally substitute occurrences of pattern in a string with replacement.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pattern : str\n",
      "     |        A regular expression.\n",
      "     |      \n",
      "     |      replacement : str\n",
      "     |        A replacement string.\n",
      "     |      \n",
      "     |      ignore_case : bool\n",
      "     |        If True then pattern will match against upper and lower case.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  head(self, rows=10, cols=200)\n",
      "     |      Analogous to Rs `head` call on a data.frame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rows : int, default=10\n",
      "     |        Number of rows starting from the topmost\n",
      "     |      cols : int, default=200\n",
      "     |        Number of columns starting from the leftmost\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        An H2OFrame.\n",
      "     |  \n",
      "     |  hist(self, breaks='Sturges', plot=True, **kwargs)\n",
      "     |      Compute a histogram over a numeric column.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      breaks: str, int, list\n",
      "     |        Can be one of \"Sturges\", \"Rice\", \"sqrt\", \"Doane\", \"FD\", \"Scott.\"\n",
      "     |        Can be a single number for the number of breaks.\n",
      "     |        Can be a list containing sthe split points, e.g., [-50,213.2123,9324834]\n",
      "     |        If breaks is \"FD\", the MAD is used over the IQR in computing bin width.\n",
      "     |      plot : bool, default=True\n",
      "     |        If True, then a plot is generated\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        If plot is False, return H2OFrame with these columns: breaks, counts, mids_true,\n",
      "     |        mids, and density; otherwise produce the plot.\n",
      "     |  \n",
      "     |  hour(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Hour-of-Day column from a msec-since-Epoch column\n",
      "     |  \n",
      "     |  ifelse(self, yes, no)\n",
      "     |      Equivalent to [y if t else n for t,y,n in zip(self,yes,no)]\n",
      "     |      \n",
      "     |      Based on the booleans in the test vector, the output has the values of the\n",
      "     |      yes and no vectors interleaved (or merged together).  All Frames must have\n",
      "     |      the same row count.  Single column frames are broadened to match wider\n",
      "     |      Frames.  Scalars are allowed, and are also broadened to match wider frames.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      test : H2OFrame (self)\n",
      "     |        Frame of values treated as booleans; may be a single column\n",
      "     |      yes : H2OFrame\n",
      "     |        Frame to use if [test] is true ; may be a scalar or single column\n",
      "     |      no : H2OFrame\n",
      "     |        Frame to use if [test] is false; may be a scalar or single column\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame of the merged yes/no Frames/scalars according to the test input frame.\n",
      "     |  \n",
      "     |  impute(self, column, method='mean', combine_method='interpolate', by=None)\n",
      "     |      Impute a column in this H2OFrame\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      column : int, str\n",
      "     |        The column to impute\n",
      "     |      method: str, default=\"mean\"\n",
      "     |        How to compute the imputation value.\n",
      "     |      combine_method: str, default=\"interpolate\"\n",
      "     |        For even samples and method=\"median\", how to combine quantiles.\n",
      "     |      by : list\n",
      "     |        Columns to group-by for computing imputation value per groups of columns.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        An H2OFrame with the desired column's NAs filled with imputed values.\n",
      "     |        Note that the returned Frame is in conceptually a new Frame, but due \n",
      "     |        to back-end optimizations is frequently not actually a copy.\n",
      "     |  \n",
      "     |  insert_missing_values(self, fraction=0.1, seed=None)\n",
      "     |      Inserting Missing Values into an H2OFrame.\n",
      "     |      *This is primarily used for testing*.\n",
      "     |      \n",
      "     |      Randomly replaces a user-specified fraction of entries in a H2O dataset with missing\n",
      "     |      values.\n",
      "     |      \n",
      "     |      WARNING: This will modify the original dataset.  Unless this is intended, this\n",
      "     |      function should only be called on a subset of the original.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fraction : float\n",
      "     |        A number between 0 and 1 indicating the fraction of entries to replace with missing.\n",
      "     |      seed : int\n",
      "     |        A random number used to select which entries to replace with missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame with missing values inserted.\n",
      "     |  \n",
      "     |  interaction(self, factors, pairwise, max_factors, min_occurrence, destination_frame=None)\n",
      "     |      Categorical Interaction Feature Creation in H2O.\n",
      "     |      Creates a frame in H2O with n-th order interaction features between categorical columns, as specified by\n",
      "     |      the user.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      factors : list\n",
      "     |          factors Factor columns (either indices or column names).\n",
      "     |      pairwise : bool\n",
      "     |        Whether to create pairwise interactions between factors (otherwise create one\n",
      "     |        higher-order interaction). Only applicable if there are 3 or more factors.\n",
      "     |      max_factors: int\n",
      "     |        Max. number of factor levels in pair-wise interaction terms (if enforced, one extra\n",
      "     |        catch-all factor will be made)\n",
      "     |      min_occurrence: int\n",
      "     |        Min. occurrence threshold for factor levels in pair-wise interaction terms\n",
      "     |      destination_frame: str, optional\n",
      "     |        A string indicating the destination key.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  is_src_in_self(self, src)\n",
      "     |  \n",
      "     |  ischaracter(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if the column is a character column, otherwise False (same as isstring)\n",
      "     |  \n",
      "     |  isfactor(self)\n",
      "     |      Test if the selection is a factor column.\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if the column is categorical; otherwise False. For String columns, the result is\n",
      "     |        False.\n",
      "     |  \n",
      "     |  isna(self)\n",
      "     |      For each row in a column, determine if it is NA or not.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Single-column H2OFrame of 1s and 0s. 1 means the value was NA.\n",
      "     |  \n",
      "     |  isnumeric(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if the column is numeric, otherwise return False\n",
      "     |  \n",
      "     |  isstring(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        True if the column is a string column, otherwise False (same as ischaracter)\n",
      "     |  \n",
      "     |  kfold_column(self, n_folds=3, seed=-1)\n",
      "     |      Build a fold assignments column for cross-validation. This call will produce a\n",
      "     |      column having the same data layout as the calling object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        n_folds : int\n",
      "     |          An integer specifying the number of validation sets to split the training data\n",
      "     |          into.\n",
      "     |        seed : int, optional\n",
      "     |          Seed for random numbers as fold IDs are randomly assigned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A single column H2OFrame with the fold assignments.\n",
      "     |  \n",
      "     |  levels(self)\n",
      "     |      Get the factor levels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A dictionary of column_name:column_levels pairs.\n",
      "     |  \n",
      "     |  lgamma(self)\n",
      "     |  \n",
      "     |  log(self)\n",
      "     |  \n",
      "     |  log10(self)\n",
      "     |  \n",
      "     |  log1p(self)\n",
      "     |  \n",
      "     |  log2(self)\n",
      "     |  \n",
      "     |  logical_negation(self)\n",
      "     |  \n",
      "     |  match(self, table, nomatch=0)\n",
      "     |      Makes a vector of the positions of (first) matches of its first argument in its second.\n",
      "     |      \n",
      "     |      :param table:\n",
      "     |      :param nomatch:\n",
      "     |      \n",
      "     |      :return: H2OFrame of one boolean column\n",
      "     |  \n",
      "     |  max(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The maximum value of all frame entries\n",
      "     |  \n",
      "     |  mean(self, na_rm=False)\n",
      "     |      Compute the mean.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        na_rm: bool, default=False\n",
      "     |          If True, then remove NAs from the computation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list containing the mean for each column (NaN for non-numeric columns).\n",
      "     |  \n",
      "     |  median(self, na_rm=False)\n",
      "     |      Compute the median.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        na_rm: bool, default=False\n",
      "     |          If True, then remove NAs from the computation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list containing the median for each column (NaN for non-numeric columns).\n",
      "     |  \n",
      "     |  merge(self, other, allLeft=True, allRite=False)\n",
      "     |      Merge two datasets based on common column names\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other: H2OFrame\n",
      "     |        Other dataset to merge.  Must have at least one column in common with self,\n",
      "     |        and all columns in common are used as the merge key.  If you want to use only a\n",
      "     |        subset of the columns in common, rename the other columns so the columns are unique\n",
      "     |        in the merged result.\n",
      "     |      allLeft: bool, default=True\n",
      "     |        If True, include all rows from the left/self frame\n",
      "     |      allRite: bool, default=True\n",
      "     |        If True, include all rows from the right/other frame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Original self frame enhanced with merged columns and rows\n",
      "     |  \n",
      "     |  min(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The minimum value of all frame entries\n",
      "     |  \n",
      "     |  modulo_kfold_column(self, n_folds=3)\n",
      "     |      Build a fold assignments column for cross-validation. Rows are assigned a fold\n",
      "     |      according to the current row number modulo n_folds.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        n_folds : int\n",
      "     |          An integer specifying the number of validation sets to split the training data\n",
      "     |          into.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A single column H2OFrame with the fold assignments.\n",
      "     |  \n",
      "     |  month(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Month column from a msec-since-Epoch column\n",
      "     |  \n",
      "     |  mult(self, matrix)\n",
      "     |      Perform matrix multiplication.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        matrix : H2OFrame\n",
      "     |          The right-hand-side matrix\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame result of the matrix multiplication\n",
      "     |  \n",
      "     |  na_omit(self)\n",
      "     |      Remove rows with NAs from the H2OFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  nchar(self)\n",
      "     |      Count the number of characters in each string of single-column H2OFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A single-column H2OFrame containing the per-row character count.\n",
      "     |  \n",
      "     |  nlevels(self)\n",
      "     |      Get the number of factor levels for this frame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A dictionary of column_name:number_levels pairs.\n",
      "     |  \n",
      "     |  pop(self, i)\n",
      "     |      Pop a column from the H2OFrame at index i\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      i : int, str\n",
      "     |        The index or name of the column to pop.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The column dropped from the frame; the frame is side-effected to lose the column\n",
      "     |  \n",
      "     |  prod(self, na_rm=False)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        na_rm : bool, default=False\n",
      "     |          True or False to remove NAs from computation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The product of the column.\n",
      "     |  \n",
      "     |  quantile(self, prob=None, combine_method='interpolate')\n",
      "     |      Compute quantiles.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      prob : list, default=[0.01,0.1,0.25,0.333,0.5,0.667,0.75,0.9,0.99]\n",
      "     |        A list of probabilities of any length.\n",
      "     |      combine_method : str, default=\"interpolate\"\n",
      "     |        For even samples, how to combine quantiles.\n",
      "     |        Should be one of [\"interpolate\", \"average\", \"low\", \"hi\"]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A new H2OFrame containing the quantiles and probabilities.\n",
      "     |  \n",
      "     |  rbind(self, data)\n",
      "     |      Combine H2O Datasets by rows.\n",
      "     |      Takes a sequence of H2O data sets and combines them by rows.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        data : H2OFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Returns this H2OFrame with data appended row-wise.\n",
      "     |  \n",
      "     |  rep_len(self, length_out)\n",
      "     |      Replicates the values in `data` in the H2O backend\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      length_out : int\n",
      "     |        Number of columns of the resulting H2OFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  round(self, digits=0)\n",
      "     |      Round doubles/floats to the given number of digits.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      digits : int\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  runif(self, seed=None)\n",
      "     |      Generate a column of random numbers drawn from a uniform distribution [0,1) and\n",
      "     |      having the same data layout as the calling H2OFrame instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      seed : int, optional\n",
      "     |        A random seed. If None, then one will be generated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Single-column H2OFrame filled with doubles sampled uniformly from [0,1).\n",
      "     |  \n",
      "     |  scale(self, center=True, scale=True)\n",
      "     |      Centers and/or scales the columns of the self._newExpr\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      center : bool, list\n",
      "     |        If True, then demean the data by the mean. If False, no shifting is done.\n",
      "     |        If a list, then shift each column by the given amount in the list.\n",
      "     |      scale : bool, list\n",
      "     |        If True, then scale the data by the column standard deviation. If False, no scaling\n",
      "     |        is done.\n",
      "     |        If a list, then scale each column by the given amount in the list.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  sd(self, na_rm=False)\n",
      "     |      Compute the standard deviation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      na_rm : bool, default=False\n",
      "     |        Remove NAs from the computation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list containing the standard deviation for each column (NaN for non-numeric\n",
      "     |        columns).\n",
      "     |  \n",
      "     |  set_level(self, level)\n",
      "     |      A method to set all column values to one of the levels.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      level : str\n",
      "     |        The level at which the column will be set (a string)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame with entries set to the desired level.\n",
      "     |  \n",
      "     |  set_levels(self, levels)\n",
      "     |      Works on a single categorical column.\n",
      "     |      New domains must be aligned with the old domains. This call has copy-on-write semantics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      levels : list\n",
      "     |        A list of strings specifying the new levels. The number of new levels must match\n",
      "     |        the number of old levels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A single-column H2OFrame with the desired levels.\n",
      "     |  \n",
      "     |  set_name(self, col=None, name=None)\n",
      "     |      Set the name of the column at the specified index.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col : int, str\n",
      "     |        Index of the column whose name is to be set; may be skipped for 1-column frames\n",
      "     |      name : str\n",
      "     |        The new name of the column to set\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Returns self.\n",
      "     |  \n",
      "     |  set_names(self, names)\n",
      "     |      Change all of this H2OFrame instance's column names.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        names : list\n",
      "     |          A list of strings equal to the number of columns in the H2OFrame.\n",
      "     |  \n",
      "     |  show(self, use_pandas=False)\n",
      "     |      Used by the H2OFrame.__repr__ method to print or display a snippet of the data frame.\n",
      "     |      If called from IPython, displays an html'ized result\n",
      "     |      Else prints a tabulate'd result\n",
      "     |  \n",
      "     |  sign(self)\n",
      "     |  \n",
      "     |  signif(self, digits=6)\n",
      "     |      Round doubles/floats to the given number of significant digits.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      digits : int, default=6\n",
      "     |        Number of significant digits to round doubles/floats.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  sin(self)\n",
      "     |  \n",
      "     |  sinh(self)\n",
      "     |  \n",
      "     |  sinpi(self)\n",
      "     |  \n",
      "     |  split_frame(self, ratios=None, destination_frames=None, seed=None)\n",
      "     |      Split a frame into distinct subsets of size determined by the given ratios.\n",
      "     |      The number of subsets is always 1 more than the number of ratios given.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        ratios : list\n",
      "     |          The fraction of rows for each split.\n",
      "     |        destination_frames : list\n",
      "     |          The names of the split frames.\n",
      "     |        seed : int\n",
      "     |          Used for selecting which H2OFrame a row will belong to.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list of H2OFrame instances\n",
      "     |  \n",
      "     |  sqrt(self)\n",
      "     |  \n",
      "     |  stratified_kfold_column(self, n_folds=3, seed=-1)\n",
      "     |      Build a fold assignment column with the constraint that each fold has the same class\n",
      "     |      distribution as the fold column.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        n_folds: int\n",
      "     |          The number of folds to build.\n",
      "     |        seed: int\n",
      "     |          A random seed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A single column H2OFrame with the fold assignments.\n",
      "     |  \n",
      "     |  stratified_split(self, test_frac=0.2, seed=-1)\n",
      "     |      Construct a column that can be used to perform a random stratified split.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        test_frac : float, default=0.2\n",
      "     |          The fraction of rows that will belong to the \"test\".\n",
      "     |        seed      : int\n",
      "     |          For seeding the random splitting.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A categorical column of two levels \"train\" and \"test\".\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |        >>> my_stratified_split = my_frame[\"response\"].stratified_split(test_frac=0.3,seed=12349453)\n",
      "     |        >>> train = my_frame[my_stratified_split==\"train\"]\n",
      "     |        >>> test  = my_frame[my_stratified_split==\"test\"]\n",
      "     |      \n",
      "     |        # check the distributions among the initial frame, and the train/test frames match\n",
      "     |        >>> my_frame[\"response\"].table()[\"Count\"] / my_frame[\"response\"].table()[\"Count\"].sum()\n",
      "     |        >>> train[\"response\"].table()[\"Count\"] / train[\"response\"].table()[\"Count\"].sum()\n",
      "     |        >>> test[\"response\"].table()[\"Count\"] / test[\"response\"].table()[\"Count\"].sum()\n",
      "     |  \n",
      "     |  strsplit(self, pattern)\n",
      "     |      Split the strings in the target column on the given pattern\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pattern : str\n",
      "     |        The split pattern.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame containing columns of the split strings.\n",
      "     |  \n",
      "     |  structure(self)\n",
      "     |      Similar to R's str method: Compactly Display the Structure of this H2OFrame.\n",
      "     |  \n",
      "     |  sub(self, pattern, replacement, ignore_case=False)\n",
      "     |      Substitute the first occurrence of pattern in a string with replacement.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pattern : str\n",
      "     |        A regular expression.\n",
      "     |      \n",
      "     |      replacement : str\n",
      "     |        A replacement string.\n",
      "     |      \n",
      "     |      ignore_case : bool\n",
      "     |        If True then pattern will match against upper and lower case.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  sum(self, na_rm=False)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The sum of all frame entries\n",
      "     |  \n",
      "     |  summary(self)\n",
      "     |      Summary: show(), plus includes min/mean/max/sigma and other rollup data\n",
      "     |  \n",
      "     |  table(self, data2=None)\n",
      "     |      Compute the counts of values appearing in a column, or co-occurence counts between\n",
      "     |      two columns.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        data2 : H2OFrame\n",
      "     |          Default is None, can be an optional single column to aggregate counts by.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame of the counts at each combination of factor levels\n",
      "     |  \n",
      "     |  tail(self, rows=10, cols=200)\n",
      "     |      Analogous to Rs `tail` call on a data.frame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rows : int, default=10\n",
      "     |        Number of rows starting from the bottommost\n",
      "     |      cols: int, default=200\n",
      "     |        Number of columns starting from the leftmost\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        An H2OFrame.\n",
      "     |  \n",
      "     |  tan(self)\n",
      "     |  \n",
      "     |  tanh(self)\n",
      "     |  \n",
      "     |  tanpi(self)\n",
      "     |  \n",
      "     |  tolower(self)\n",
      "     |      Translate characters from upper to lower case for a particular column\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  toupper(self)\n",
      "     |      Translate characters from lower to upper case for a particular column\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame\n",
      "     |  \n",
      "     |  transpose(self)\n",
      "     |      Transpose rows and columns of H2OFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The transpose of the input frame.\n",
      "     |  \n",
      "     |  trigamma(self)\n",
      "     |  \n",
      "     |  trim(self)\n",
      "     |      Trim white space on the left and right of strings in a single-column H2OFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame with trimmed strings.\n",
      "     |  \n",
      "     |  trunc(self)\n",
      "     |  \n",
      "     |  type(self, name)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The type for a named column\n",
      "     |  \n",
      "     |  unique(self)\n",
      "     |      Extract the unique values in the column.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame of just the unique values in the column.\n",
      "     |  \n",
      "     |  var(self, y=None, use='everything')\n",
      "     |      Compute the variance, or co-variance matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : H2OFrame, default=None\n",
      "     |        If y is None, then the variance is computed for self. If self has more than one\n",
      "     |        column, then the covariance matrix is returned.\n",
      "     |        If y is not None, then the covariance between self and y is computed (self and y\n",
      "     |        must therefore both be single columns).\n",
      "     |      use : str\n",
      "     |        One of \"everything\", \"complete.obs\", or \"all.obs\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The covariance matrix of the columns in this H2OFrame if y is given, or a eagerly\n",
      "     |        computed scalar if y is not given.\n",
      "     |  \n",
      "     |  week(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Week column from a msec-since-Epoch column\n",
      "     |  \n",
      "     |  which(self)\n",
      "     |      Equivalent to [ index for index,value in enumerate(self) if value ]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Single-column H2OFrame filled with 0-based indices for which the elements are not\n",
      "     |      zero.\n",
      "     |  \n",
      "     |  year(self)\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Year column from a msec-since-Epoch column\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_python(python_obj, destination_frame='', header=(-1, 0, 1), separator='', column_names=None, column_types=None, na_strings=None)\n",
      "     |      Properly handle native python data types. For a discussion of the rules and\n",
      "     |      permissible data types please refer to the main documentation for H2OFrame.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        python_obj : tuple, list, dict, collections.OrderedDict\n",
      "     |          If a nested list/tuple, then each nested collection is a column.\n",
      "     |        destination_frame : str, optional\n",
      "     |          The unique hex key assigned to the imported file. If none is given, a key will\n",
      "     |          automatically be generated.\n",
      "     |        header : int, optional\n",
      "     |         -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "     |        sep : str, optional\n",
      "     |          The field separator character. Values on each line of the file are separated by\n",
      "     |          this character. If sep = \"\", the parser will automatically detect the separator.\n",
      "     |        col_names : list, optional\n",
      "     |          A list of column names for the file.\n",
      "     |        col_types : list or dict, optional\n",
      "     |          A list of types or a dictionary of column names to types to specify whether columns\n",
      "     |          should be forced to a certain type upon import parsing. If a list, the types for\n",
      "     |          elements that are None will be guessed. The possible types a column may have are:\n",
      "     |              \"unknown\" - this will force the column to be parsed as all NA\n",
      "     |              \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "     |              \"string\"  - force the column to be parsed as a string\n",
      "     |              \"numeric\" - force the column to be parsed as numeric. H2O will handle the\n",
      "     |                          compression of the numeric data in the optimal manner.\n",
      "     |              \"enum\"    - force the column to be parsed as a categorical column.\n",
      "     |              \"time\"    - force the column to be parsed as a time column. H2O will attempt to\n",
      "     |                          parse the following list of date time formats.\n",
      "     |                            date:\n",
      "     |                              \"yyyy-MM-dd\"\n",
      "     |                              \"yyyy MM dd\"\n",
      "     |                              \"dd-MMM-yy\"\n",
      "     |                              \"dd MMM yy\"\n",
      "     |                            time:\n",
      "     |                              \"HH:mm:ss\"\n",
      "     |                              \"HH:mm:ss:SSS\"\n",
      "     |                              \"HH:mm:ss:SSSnnnnnn\"\n",
      "     |                              \"HH.mm.ss\"\n",
      "     |                              \"HH.mm.ss.SSS\"\n",
      "     |                              \"HH.mm.ss.SSSnnnnnn\"\n",
      "     |                          Times can also contain \"AM\" or \"PM\".\n",
      "     |        na_strings : list or dict, optional\n",
      "     |          A list of strings, or a list of lists of strings (one list per column), or a\n",
      "     |          dictionary of column names to strings which are to be interpreted as missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A new H2OFrame instance.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |        >>> l = [[1,2,3,4,5], [99,123,51233,321]]\n",
      "     |        >>> l = H2OFrame(l)\n",
      "     |        >>> l\n",
      "     |  \n",
      "     |  get_frame(frame_id)\n",
      "     |      Create an H2OFrame mapped to an existing id in the cluster.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame that points to a pre-existing big data H2OFrame in the cluster\n",
      "     |  \n",
      "     |  mktime(year=1970, month=0, day=0, hour=0, minute=0, second=0, msec=0)\n",
      "     |      All units are zero-based (including months and days).\n",
      "     |      Missing year is 1970.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |        year : int, H2OFrame\n",
      "     |        month: int, H2OFrame\n",
      "     |        day : int, H2OFrame\n",
      "     |        hour : int, H2OFrame\n",
      "     |        minute : int, H2OFrame\n",
      "     |        second : int, H2OFrame\n",
      "     |        msec : int, H2OFrame\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        H2OFrame of one column containing the date in millis since the epoch.\n",
      "     |  \n",
      "     |  temp_ctr()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  col_names\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list of column names.\n",
      "     |  \n",
      "     |  columns\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A list of column names.\n",
      "     |  \n",
      "     |  dim\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The number of rows and columns in the H2OFrame as a list [rows, cols].\n",
      "     |  \n",
      "     |  frame_id\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        Get the name of this frame.\n",
      "     |  \n",
      "     |  names\n",
      "     |      Retrieve the column names (one name per H2OVec) for this H2OFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A str list of column names\n",
      "     |  \n",
      "     |  ncol\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The number of columns in the H2OFrame.\n",
      "     |  \n",
      "     |  nrow\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        The number of rows in the H2OFrame.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A tuple (nrow, ncol)\n",
      "     |  \n",
      "     |  types\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |        A dictionary of column_name-type pairs.\n",
      "    \n",
      "    class H2OTwoDimTable(__builtin__.object)\n",
      "     |  A class representing an 2D table (for pretty printing output).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, item)\n",
      "     |  \n",
      "     |  __init__(self, row_header=None, col_header=None, col_types=None, table_header=None, raw_cell_values=None, col_formats=None, cell_values=None, table_description=None)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  show(self, header=True)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['H2OFrame', 'H2OConnection', 'H2OTwoDimTable', 'GroupBy']\n",
      "    __version__ = '3.7.0.3248'\n",
      "\n",
      "VERSION\n",
      "    3.7.0.3248\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help() can be used on H2O functions and models. Jupyter's builtin shift-tab functionality also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGradientBoostingEstimator in module h2o.estimators.gbm:\n",
      "\n",
      "class H2OGradientBoostingEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Builds gradient boosted classification trees, and gradient boosted regression trees on\n",
      " |  a parsed data set. The default distribution function will guess the model type based on\n",
      " |  the response column type run properly the response column must be an numeric for\n",
      " |  \"gaussian\" or an enum for \"bernoulli\" or \"multinomial\".\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  model_id : str, optional\n",
      " |    The unique id assigned to the resulting model. If none is given, an id will\n",
      " |    automatically be generated.\n",
      " |  distribution : str\n",
      " |     The distribution function of the response. Must be \"AUTO\", \"bernoulli\",\n",
      " |     \"multinomial\", \"poisson\", \"gamma\", \"tweedie\" or \"gaussian\"\n",
      " |  tweedie_power : float\n",
      " |    Tweedie power (only for Tweedie distribution, must be between 1 and 2)\n",
      " |  ntrees : int\n",
      " |    A non-negative integer that determines the number of trees to grow.\n",
      " |  max_depth : int\n",
      " |    Maximum depth to grow the tree.\n",
      " |  min_rows : int\n",
      " |    Minimum number of rows to assign to terminal nodes.\n",
      " |  learn_rate : float\n",
      " |    Learning rate (from 0.0 to 1.0)\n",
      " |  sample_rate : float\n",
      " |    Row sample rate (from 0.0 to 1.0)\n",
      " |  col_sample_rate : float\n",
      " |    Column sample rate (from 0.0 to 1.0)\n",
      " |  nbins : int\n",
      " |    For numerical columns (real/int), build a histogram of (at least) this many bins, then\n",
      " |    split at the best point.\n",
      " |  nbins_top_level : int\n",
      " |    For numerical columns (real/int), build a histogram of (at most) this many bins at the\n",
      " |    root level, then decrease by factor of two per level.\n",
      " |  nbins_cats : int\n",
      " |    For categorical columns (factors), build a histogram of this many bins, then split at\n",
      " |    the best point. Higher values can lead to more overfitting.\n",
      " |  balance_classes : bool\n",
      " |    logical, indicates whether or not to balance training data class counts via\n",
      " |    over/under-sampling (for imbalanced data)\n",
      " |  max_after_balance_size : float\n",
      " |    Maximum relative size of the training data after balancing class counts\n",
      " |    (can be less than 1.0). Ignored if balance_classes is False, which is the\n",
      " |    default behavior.\n",
      " |  seed : int\n",
      " |    Seed for random numbers (affects sampling when balance_classes=T)\n",
      " |  build_tree_one_node : bool\n",
      " |    Run on one node only; no network overhead but fewer cpus used.\n",
      " |    Suitable for small datasets.\n",
      " |  nfolds : int, optional\n",
      " |    Number of folds for cross-validation. If nfolds >= 2, then validation must\n",
      " |    remain empty.\n",
      " |  fold_assignment : str\n",
      " |    Cross-validation fold assignment scheme, if fold_column is not specified.\n",
      " |    Must be \"AUTO\", \"Random\" or \"Modulo\"\n",
      " |  keep_cross_validation_predictions : bool\n",
      " |    Whether to keep the predictions of the cross-validation models\n",
      " |  score_each_iteration : bool\n",
      " |    Attempts to score each tree.\n",
      " |  stopping_rounds : int\n",
      " |    Early stopping based on convergence of stopping_metric.\n",
      " |    Stop if simple moving average of length k of the stopping_metric does not improve\n",
      " |    (by stopping_tolerance) for k=stopping_rounds scoring events.\n",
      " |    Can only trigger after at least 2k scoring events. Use 0 to disable.\n",
      " |  stopping_metric : str\n",
      " |    Metric to use for convergence checking, only for _stopping_rounds > 0\n",
      " |    Can be one of \"AUTO\", \"deviance\", \"logloss\", \"MSE\", \"AUC\", \"r2\", \"misclassification\".\n",
      " |  stopping_tolerance : float\n",
      " |    Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |    A new H2OGradientBoostedEstimator object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGradientBoostingEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_id=None, distribution=None, tweedie_power=None, ntrees=None, max_depth=None, min_rows=None, learn_rate=None, nbins=None, sample_rate=None, col_sample_rate=None, nbins_top_level=None, nbins_cats=None, balance_classes=None, max_after_balance_size=None, seed=None, build_tree_one_node=None, nfolds=None, fold_assignment=None, keep_cross_validation_predictions=None, stopping_rounds=None, stopping_metric=None, stopping_tolerance=None, score_each_iteration=None, checkpoint=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  balance_classes\n",
      " |  \n",
      " |  build_tree_one_node\n",
      " |  \n",
      " |  checkpoint\n",
      " |  \n",
      " |  col_sample_rate\n",
      " |  \n",
      " |  distribution\n",
      " |  \n",
      " |  fold_assignment\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |  \n",
      " |  learn_rate\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |  \n",
      " |  max_depth\n",
      " |  \n",
      " |  min_rows\n",
      " |  \n",
      " |  nbins\n",
      " |  \n",
      " |  nbins_cats\n",
      " |  \n",
      " |  nbins_top_level\n",
      " |  \n",
      " |  nfolds\n",
      " |  \n",
      " |  ntrees\n",
      " |  \n",
      " |  sample_rate\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |  \n",
      " |  seed\n",
      " |  \n",
      " |  stopping_metric\n",
      " |  \n",
      " |  stopping_rounds\n",
      " |  \n",
      " |  stopping_tolerance\n",
      " |  \n",
      " |  tweedie_power\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  build_model(self, algo_params)\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        X : H2OFrame\n",
      " |          An H2OFrame consisting of the predictor variables.\n",
      " |        y : H2OFrame, optional\n",
      " |          An H2OFrame consisting of the response variable.\n",
      " |        params : optional\n",
      " |          Extra arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Useful method for obtaining parameters for this estimator. Used primarily for\n",
      " |      sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        deep : bool, optional\n",
      " |          If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        parms : dict\n",
      " |          A dictionary of parameters that will be set on this model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        Returns self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Asynchronous model build by specifying the predictor columns, response column, and any\n",
      " |      additional frame-specific values.\n",
      " |      \n",
      " |      To block for results, call join.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        x : list\n",
      " |          A list of column names or indices indicating the predictor columns.\n",
      " |        y : str\n",
      " |          An index or a column name indicating the response column.\n",
      " |        training_frame : H2OFrame\n",
      " |          The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |        offset_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the offsets.\n",
      " |        fold_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |        weights_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row weights.\n",
      " |        validation_frame : H2OFrame, optional\n",
      " |          H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the H2O model by specifying the predictor columns, response column, and any\n",
      " |      additional frame-specific values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |        x : list\n",
      " |          A list of column names or indices indicating the predictor columns.\n",
      " |        y : str\n",
      " |          An index or a column name indicating the response column.\n",
      " |        training_frame : H2OFrame\n",
      " |          The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |        offset_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the offsets.\n",
      " |        fold_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |        weights_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row weights.\n",
      " |        validation_frame : H2OFrame, optional\n",
      " |          H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the AIC value for the training data.\n",
      " |      :param valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      :return: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the AUC value for the training data.\n",
      " |      :param valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      :return: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector\n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      :return: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding\n",
      " |  \n",
      " |  coef(self)\n",
      " |      :return: Return the coefficients for this model.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      :return: Return the normalized coefficients\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_pojo(self, path='')\n",
      " |      Download the POJO for this model to the directory specified by path (no trailing slash!).\n",
      " |      If path is \"\", then dump to screen.\n",
      " |      :param model: Retrieve this model's scoring POJO.\n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :return: None\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      :return: A model or list of models.\n",
      " |  \n",
      " |  giniCoef(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini Coefficient(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      :return: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      :return:  True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Log Loss value for the training data.\n",
      " |      :param valid: If valid is True, then return the Log Loss value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Log Loss value for the cross validation data.\n",
      " |      :return: The Log Loss for this binomial model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      :return: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param test_data: Data set for which model metrics shall be computed against. Both train and valid arguments are ignored if test_data is not None.\n",
      " |      :param train: Report the training metrics for the model. If the test_data is the training data, the training metrics are returned.\n",
      " |      :param valid: Report the validation metrics for the model. If train and valid are True, then it defaults to True.\n",
      " |      :return: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the MSE(s).\n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the MSE value for the training data.\n",
      " |      :param valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      :return: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the null dof for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param valid: Get the null dof for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param:  train Get the null deviance for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param:  valid Get the null deviance for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients)\n",
      " |      :return: None\n",
      " |  \n",
      " |  predict(self, test_data)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param test_data: Data to be predicted on.\n",
      " |      :return: A new H2OFrame filled with predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R^2 for this regression model.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var,\n",
      " |      where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\", \"valid\",\n",
      " |      and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      :return: The R^2 for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the residual dof for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param valid: Get the residual dof for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the residual deviance for the training set. If both train and valid are False, then train is selected by default.\n",
      " |      :param valid: Get the residual deviance for the validation set. If both train and valid are True, then train is selected by default.\n",
      " |      :return: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      Retrieve Model Score History\n",
      " |      :return: the score history (H2OTwoDimTable)\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type\n",
      " |      \n",
      " |      :return: None\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |      \n",
      " |      :return:\n",
      " |  \n",
      " |  varimp(self, return_list=False)\n",
      " |      Pretty print the variable importances, or return them in a list\n",
      " |      :param return_list: if True, then return the variable importances in an list (ordered from most important to least\n",
      " |      important). Each entry in the list is a 4-tuple of (variable, relative_importance, scaled_importance, percentage).\n",
      " |      :return: None or ordered list\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix\n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      :return: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      :return: The model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Get the full specification of all parameters.\n",
      " |      \n",
      " |      :return: a dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  model_id\n",
      " |      :return: Retrieve this model's identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :return: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :return: A list of models\n",
      "\n",
      "Help on function import_file in module h2o.h2o:\n",
      "\n",
      "import_file(path=None, destination_frame='', parse=True, header=(-1, 0, 1), sep='', col_names=None, col_types=None, na_strings=None)\n",
      "    Have H2O import a dataset into memory. The path to the data must be a valid path for\n",
      "    each node in the H2O cluster. If some node in the H2O cluster cannot see the file, then\n",
      "    an exception will be thrown by the H2O cluster.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "      path : str\n",
      "        A path specifying the location of the data to import.\n",
      "      destination_frame : str, optional\n",
      "        The unique hex key assigned to the imported file. If none is given, a key will\n",
      "        automatically be generated.\n",
      "      parse : bool, optional\n",
      "        A logical value indicating whether the file should be parsed after import.\n",
      "      header : int, optional\n",
      "       -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "      sep : str, optional\n",
      "        The field separator character. Values on each line of the file are separated by this\n",
      "        character. If sep = \"\", the parser will automatically detect the separator.\n",
      "      col_names : list, optional\n",
      "        A list of column names for the file.\n",
      "      col_types : list or dict, optional\n",
      "        A list of types or a dictionary of column names to types to specify whether columns\n",
      "        should be forced to a certain type upon import parsing. If a list, the types for\n",
      "        elements that are None will be guessed. The possible types a column may have are:\n",
      "            \"unknown\" - this will force the column to be parsed as all NA\n",
      "            \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            \"string\"  - force the column to be parsed as a string\n",
      "            \"numeric\" - force the column to be parsed as numeric. H2O will handle the\n",
      "                        compression of the numeric data in the optimal manner.\n",
      "            \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            \"time\"    - force the column to be parsed as a time column. H2O will attempt to\n",
      "                        parse the following list of date time formats.\n",
      "                          date:\n",
      "                            \"yyyy-MM-dd\"\n",
      "                            \"yyyy MM dd\"\n",
      "                            \"dd-MMM-yy\"\n",
      "                            \"dd MMM yy\"\n",
      "                          time:\n",
      "                            \"HH:mm:ss\"\n",
      "                            \"HH:mm:ss:SSS\"\n",
      "                            \"HH:mm:ss:SSSnnnnnn\"\n",
      "                            \"HH.mm.ss\"\n",
      "                            \"HH.mm.ss.SSS\"\n",
      "                            \"HH.mm.ss.SSSnnnnnn\"\n",
      "                        Times can also contain \"AM\" or \"PM\".\n",
      "      na_strings : list or dict, optional\n",
      "        A list of strings, or a list of lists of strings (one list per column), or a\n",
      "        dictionary of column names to strings which are to be interpreted as missing values.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "      A new H2OFrame instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "help(H2OGradientBoostingEstimator)\n",
    "help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##H2O GBM and RF\n",
    "\n",
    "While H2O Gradient Boosting Methods and H2O Random Forest have many flexible parameters options, they were designed to be just as easy to use as the other supervised training methods in H2O. Early stopping, automatic data standardization and handling of categorical variables and missing values and adaptive learning rates (per weight) reduce the amount of parameters the user has to specify. Often, it's just the number and sizes of hidden layers, the number of epochs and the activation function and maybe some regularization techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting started\n",
    "\n",
    "We begin by importing our data into H2OFrames, which operate similarly in function to pandas DataFrames but exist on the H2O cloud itself.  \n",
    "\n",
    "In this case, the H2O cluster is running on our laptops. Data files are imported by their relative locations to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "covtype_df = h2o.upload_file(\"../data/covtype.full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the full covertype dataset (581k rows, 13 columns, 10 numerical, 3 categorical) and then split the data 3 ways:  \n",
    "  \n",
    "60% for training  \n",
    "20% for validation (hyper parameter tuning)  \n",
    "20% for final testing  \n",
    "\n",
    " We will train a data set on one set and use the others to test the validity of the model by ensuring that it can predict accurately on data the model has not been shown.  \n",
    " \n",
    " The second set will be used for validation most of the time.  \n",
    " \n",
    " The third set will be withheld until the end, to ensure that our validation accuracy is consistent with data we have never seen during the iterative process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data as described above\n",
    "train, valid, test = covtype_df.split_frame([0.6, 0.2], seed=1234)\n",
    "\n",
    "#Prepare predictors and response columns\n",
    "covtype_X = covtype_df.col_names[:-1]     #last column is Cover_Type, our desired response variable \n",
    "covtype_y = covtype_df.col_names[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The First Random Forest\n",
    "We build our first model with the following parameters\n",
    "\n",
    "**model_id:** Not required, but allows us to easily find our model in the [Flow](http://localhost:54321/) interface  \n",
    "**ntrees:** Maximum number of trees used by the random forest. Default value is 50. We can afford to increase this, as our early-stopping criterion will decide when the random forest is sufficiently accurate.  \n",
    "**stopping_rounds:** Stopping criterion described above. Stops fitting new trees when 2-tree rolling average is within 0.001 (default) of the two prior rolling averages. Can be thought of as a convergence setting.  \n",
    "**score_each_teration:** predict against training and validation for each tree. Default will skip several.  \n",
    "**seed:** set the randomization seed so we can reproduce results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model Construction\n",
    "H2O in Python is designed to be very similar in look and feel to to scikit-learn. Models are initialized individually with desired or default parameters and then trained on data.  \n",
    "\n",
    "**Note that the below example uses model.train() as opposed the traditional model.fit()**  \n",
    "This is because h2o-py takes column indices for the feature and response columns AND the whole data frame, while scikit-learn takes in a feature frame and a response frame.\n",
    "\n",
    "H2O supports model.fit() so that it can be incorporated into a scikit-learn pipeline, but we advise using train() in all other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "drf Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "rf_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the progress bar does not behave linearly. H2O estimates completion time initially based on the number of epochs specified. However, convergence can allow for early stops, in which case the bar jumps to 100%.\n",
    "\n",
    "We can view information about the model in [Flow](http://localhost:54321/) or within Python. To find more information in Flow, enter `getModel \"rf_covType_v1\"` into a cell and run in place pressing Ctrl-Enter. Alternatively, you can click on the Models tab, select List All Models, and click on the model named \"rf_covType_v1\" as specified in our model construction above.\n",
    "\n",
    "In Python, we can run *rf_v1.summary()* to get some basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>154.0</td>\n",
       "<td>8685760.0</td>\n",
       "<td>18.0</td>\n",
       "<td>20.0</td>\n",
       "<td>19.948051</td>\n",
       "<td>481.0</td>\n",
       "<td>14114.0</td>\n",
       "<td>4856.169</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    154                8.68576e+06            18           20           19.9481       481           14114         4856.17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at validation statistics, we can use the scoring history function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_MSE</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_MSE</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:28</td>\n",
       "      <td>2.167 sec</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157191</td>\n",
       "      <td>3.773954</td>\n",
       "      <td>0.160639</td>\n",
       "      <td>0.157481</td>\n",
       "      <td>3.773075</td>\n",
       "      <td>0.165623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:30</td>\n",
       "      <td>3.628 sec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.144252</td>\n",
       "      <td>3.218432</td>\n",
       "      <td>0.150622</td>\n",
       "      <td>0.094394</td>\n",
       "      <td>1.061510</td>\n",
       "      <td>0.113763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:31</td>\n",
       "      <td>4.893 sec</td>\n",
       "      <td>3</td>\n",
       "      <td>0.133442</td>\n",
       "      <td>2.870879</td>\n",
       "      <td>0.136207</td>\n",
       "      <td>0.077862</td>\n",
       "      <td>0.535113</td>\n",
       "      <td>0.091070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:32</td>\n",
       "      <td>6.256 sec</td>\n",
       "      <td>4</td>\n",
       "      <td>0.119160</td>\n",
       "      <td>2.313463</td>\n",
       "      <td>0.126116</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.379240</td>\n",
       "      <td>0.082469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:34</td>\n",
       "      <td>7.687 sec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109254</td>\n",
       "      <td>1.930477</td>\n",
       "      <td>0.117807</td>\n",
       "      <td>0.068963</td>\n",
       "      <td>0.316427</td>\n",
       "      <td>0.077975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:35</td>\n",
       "      <td>9.200 sec</td>\n",
       "      <td>6</td>\n",
       "      <td>0.100706</td>\n",
       "      <td>1.556173</td>\n",
       "      <td>0.110796</td>\n",
       "      <td>0.068007</td>\n",
       "      <td>0.289077</td>\n",
       "      <td>0.076465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:37</td>\n",
       "      <td>10.778 sec</td>\n",
       "      <td>7</td>\n",
       "      <td>0.094270</td>\n",
       "      <td>1.267866</td>\n",
       "      <td>0.105162</td>\n",
       "      <td>0.067546</td>\n",
       "      <td>0.275304</td>\n",
       "      <td>0.075556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:38</td>\n",
       "      <td>12.436 sec</td>\n",
       "      <td>8</td>\n",
       "      <td>0.089282</td>\n",
       "      <td>1.057529</td>\n",
       "      <td>0.100625</td>\n",
       "      <td>0.067060</td>\n",
       "      <td>0.267718</td>\n",
       "      <td>0.074733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:40</td>\n",
       "      <td>14.195 sec</td>\n",
       "      <td>9</td>\n",
       "      <td>0.084504</td>\n",
       "      <td>0.888560</td>\n",
       "      <td>0.095604</td>\n",
       "      <td>0.065910</td>\n",
       "      <td>0.257667</td>\n",
       "      <td>0.072966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:42</td>\n",
       "      <td>16.027 sec</td>\n",
       "      <td>10</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.757980</td>\n",
       "      <td>0.091451</td>\n",
       "      <td>0.064802</td>\n",
       "      <td>0.250031</td>\n",
       "      <td>0.071877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:48</td>\n",
       "      <td>22.244 sec</td>\n",
       "      <td>13</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.492678</td>\n",
       "      <td>0.084470</td>\n",
       "      <td>0.064647</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>0.070882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:51</td>\n",
       "      <td>24.461 sec</td>\n",
       "      <td>14</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.445034</td>\n",
       "      <td>0.082546</td>\n",
       "      <td>0.064438</td>\n",
       "      <td>0.238094</td>\n",
       "      <td>0.070556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:53</td>\n",
       "      <td>26.766 sec</td>\n",
       "      <td>15</td>\n",
       "      <td>0.071405</td>\n",
       "      <td>0.402042</td>\n",
       "      <td>0.080650</td>\n",
       "      <td>0.063989</td>\n",
       "      <td>0.236154</td>\n",
       "      <td>0.069896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:54:55</td>\n",
       "      <td>29.201 sec</td>\n",
       "      <td>16</td>\n",
       "      <td>0.070192</td>\n",
       "      <td>0.370160</td>\n",
       "      <td>0.079101</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.234756</td>\n",
       "      <td>0.069467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:00</td>\n",
       "      <td>33.708 sec</td>\n",
       "      <td>17</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.348401</td>\n",
       "      <td>0.078050</td>\n",
       "      <td>0.063378</td>\n",
       "      <td>0.233950</td>\n",
       "      <td>0.069175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:02</td>\n",
       "      <td>36.242 sec</td>\n",
       "      <td>18</td>\n",
       "      <td>0.068944</td>\n",
       "      <td>0.330597</td>\n",
       "      <td>0.077525</td>\n",
       "      <td>0.063468</td>\n",
       "      <td>0.233199</td>\n",
       "      <td>0.069321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:05</td>\n",
       "      <td>38.986 sec</td>\n",
       "      <td>19</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>0.314450</td>\n",
       "      <td>0.076876</td>\n",
       "      <td>0.063334</td>\n",
       "      <td>0.232641</td>\n",
       "      <td>0.069098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:08</td>\n",
       "      <td>41.785 sec</td>\n",
       "      <td>20</td>\n",
       "      <td>0.067802</td>\n",
       "      <td>0.302317</td>\n",
       "      <td>0.075867</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>0.232101</td>\n",
       "      <td>0.068704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:11</td>\n",
       "      <td>44.726 sec</td>\n",
       "      <td>21</td>\n",
       "      <td>0.067567</td>\n",
       "      <td>0.292937</td>\n",
       "      <td>0.075326</td>\n",
       "      <td>0.063294</td>\n",
       "      <td>0.232556</td>\n",
       "      <td>0.068858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:14</td>\n",
       "      <td>47.754 sec</td>\n",
       "      <td>22</td>\n",
       "      <td>0.067099</td>\n",
       "      <td>0.283573</td>\n",
       "      <td>0.074832</td>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.232164</td>\n",
       "      <td>0.068412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp    duration  number_of_trees  training_MSE  \\\n",
       "0      2015-11-07 00:54:28   2.167 sec                1      0.157191   \n",
       "1      2015-11-07 00:54:30   3.628 sec                2      0.144252   \n",
       "2      2015-11-07 00:54:31   4.893 sec                3      0.133442   \n",
       "3      2015-11-07 00:54:32   6.256 sec                4      0.119160   \n",
       "4      2015-11-07 00:54:34   7.687 sec                5      0.109254   \n",
       "5      2015-11-07 00:54:35   9.200 sec                6      0.100706   \n",
       "6      2015-11-07 00:54:37  10.778 sec                7      0.094270   \n",
       "7      2015-11-07 00:54:38  12.436 sec                8      0.089282   \n",
       "8      2015-11-07 00:54:40  14.195 sec                9      0.084504   \n",
       "9      2015-11-07 00:54:42  16.027 sec               10      0.080621   \n",
       ".. ..                  ...         ...              ...           ...   \n",
       "12     2015-11-07 00:54:48  22.244 sec               13      0.074238   \n",
       "13     2015-11-07 00:54:51  24.461 sec               14      0.072855   \n",
       "14     2015-11-07 00:54:53  26.766 sec               15      0.071405   \n",
       "15     2015-11-07 00:54:55  29.201 sec               16      0.070192   \n",
       "16     2015-11-07 00:55:00  33.708 sec               17      0.069417   \n",
       "17     2015-11-07 00:55:02  36.242 sec               18      0.068944   \n",
       "18     2015-11-07 00:55:05  38.986 sec               19      0.068407   \n",
       "19     2015-11-07 00:55:08  41.785 sec               20      0.067802   \n",
       "20     2015-11-07 00:55:11  44.726 sec               21      0.067567   \n",
       "21     2015-11-07 00:55:14  47.754 sec               22      0.067099   \n",
       "\n",
       "    training_logloss  training_classification_error  validation_MSE  \\\n",
       "0           3.773954                       0.160639        0.157481   \n",
       "1           3.218432                       0.150622        0.094394   \n",
       "2           2.870879                       0.136207        0.077862   \n",
       "3           2.313463                       0.126116        0.072011   \n",
       "4           1.930477                       0.117807        0.068963   \n",
       "5           1.556173                       0.110796        0.068007   \n",
       "6           1.267866                       0.105162        0.067546   \n",
       "7           1.057529                       0.100625        0.067060   \n",
       "8           0.888560                       0.095604        0.065910   \n",
       "9           0.757980                       0.091451        0.064802   \n",
       "..               ...                            ...             ...   \n",
       "12          0.492678                       0.084470        0.064647   \n",
       "13          0.445034                       0.082546        0.064438   \n",
       "14          0.402042                       0.080650        0.063989   \n",
       "15          0.370160                       0.079101        0.063598   \n",
       "16          0.348401                       0.078050        0.063378   \n",
       "17          0.330597                       0.077525        0.063468   \n",
       "18          0.314450                       0.076876        0.063334   \n",
       "19          0.302317                       0.075867        0.063119   \n",
       "20          0.292937                       0.075326        0.063294   \n",
       "21          0.283573                       0.074832        0.063131   \n",
       "\n",
       "    validation_logloss  validation_classification_error  \n",
       "0             3.773075                         0.165623  \n",
       "1             1.061510                         0.113763  \n",
       "2             0.535113                         0.091070  \n",
       "3             0.379240                         0.082469  \n",
       "4             0.316427                         0.077975  \n",
       "5             0.289077                         0.076465  \n",
       "6             0.275304                         0.075556  \n",
       "7             0.267718                         0.074733  \n",
       "8             0.257667                         0.072966  \n",
       "9             0.250031                         0.071877  \n",
       "..                 ...                              ...  \n",
       "12            0.240304                         0.070882  \n",
       "13            0.238094                         0.070556  \n",
       "14            0.236154                         0.069896  \n",
       "15            0.234756                         0.069467  \n",
       "16            0.233950                         0.069175  \n",
       "17            0.233199                         0.069321  \n",
       "18            0.232641                         0.069098  \n",
       "19            0.232101                         0.068704  \n",
       "20            0.232556                         0.068858  \n",
       "21            0.232164                         0.068412  \n",
       "\n",
       "[22 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1.score_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the hit ratio table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-7 Hit Ratios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9315878</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9995283</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9997427</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.931588\n",
       "2    0.99711\n",
       "3    0.999528\n",
       "4    0.999743\n",
       "5    0.999828\n",
       "6    0.999828\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Now for GBM\n",
    "\n",
    "First we will use all default settings, then make some changes to improve our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v1 = H2OGradientBoostingEstimator(\n",
    "    model_id=\"gbm_covType_v1\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_MSE</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_MSE</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:22</td>\n",
       "      <td>1.454 sec</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646936</td>\n",
       "      <td>1.640322</td>\n",
       "      <td>0.264529</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>1.641737</td>\n",
       "      <td>0.268151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:23</td>\n",
       "      <td>2.584 sec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.575810</td>\n",
       "      <td>1.441639</td>\n",
       "      <td>0.259892</td>\n",
       "      <td>0.576546</td>\n",
       "      <td>1.443982</td>\n",
       "      <td>0.263589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:24</td>\n",
       "      <td>3.624 sec</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516175</td>\n",
       "      <td>1.295177</td>\n",
       "      <td>0.258498</td>\n",
       "      <td>0.517202</td>\n",
       "      <td>1.298256</td>\n",
       "      <td>0.262440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:29</td>\n",
       "      <td>8.088 sec</td>\n",
       "      <td>8</td>\n",
       "      <td>0.331017</td>\n",
       "      <td>0.897133</td>\n",
       "      <td>0.247464</td>\n",
       "      <td>0.332998</td>\n",
       "      <td>0.902404</td>\n",
       "      <td>0.251797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:34</td>\n",
       "      <td>13.860 sec</td>\n",
       "      <td>14</td>\n",
       "      <td>0.240376</td>\n",
       "      <td>0.703644</td>\n",
       "      <td>0.239162</td>\n",
       "      <td>0.242904</td>\n",
       "      <td>0.710344</td>\n",
       "      <td>0.243100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:43</td>\n",
       "      <td>22.080 sec</td>\n",
       "      <td>23</td>\n",
       "      <td>0.190174</td>\n",
       "      <td>0.583091</td>\n",
       "      <td>0.224983</td>\n",
       "      <td>0.193166</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.229979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:55:55</td>\n",
       "      <td>34.799 sec</td>\n",
       "      <td>37</td>\n",
       "      <td>0.161117</td>\n",
       "      <td>0.505595</td>\n",
       "      <td>0.205317</td>\n",
       "      <td>0.164692</td>\n",
       "      <td>0.515542</td>\n",
       "      <td>0.211883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2015-11-07 00:56:08</td>\n",
       "      <td>47.474 sec</td>\n",
       "      <td>50</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>0.470053</td>\n",
       "      <td>0.192291</td>\n",
       "      <td>0.152370</td>\n",
       "      <td>0.481191</td>\n",
       "      <td>0.199439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  number_of_trees  training_MSE  \\\n",
       "0    2015-11-07 00:55:22   1.454 sec                1      0.646936   \n",
       "1    2015-11-07 00:55:23   2.584 sec                2      0.575810   \n",
       "2    2015-11-07 00:55:24   3.624 sec                3      0.516175   \n",
       "3    2015-11-07 00:55:29   8.088 sec                8      0.331017   \n",
       "4    2015-11-07 00:55:34  13.860 sec               14      0.240376   \n",
       "5    2015-11-07 00:55:43  22.080 sec               23      0.190174   \n",
       "6    2015-11-07 00:55:55  34.799 sec               37      0.161117   \n",
       "7    2015-11-07 00:56:08  47.474 sec               50      0.148453   \n",
       "\n",
       "   training_logloss  training_classification_error  validation_MSE  \\\n",
       "0          1.640322                       0.264529        0.647347   \n",
       "1          1.441639                       0.259892        0.576546   \n",
       "2          1.295177                       0.258498        0.517202   \n",
       "3          0.897133                       0.247464        0.332998   \n",
       "4          0.703644                       0.239162        0.242904   \n",
       "5          0.583091                       0.224983        0.193166   \n",
       "6          0.505595                       0.205317        0.164692   \n",
       "7          0.470053                       0.192291        0.152370   \n",
       "\n",
       "   validation_logloss  validation_classification_error  \n",
       "0            1.641737                         0.268151  \n",
       "1            1.443982                         0.263589  \n",
       "2            1.298256                         0.262440  \n",
       "3            0.902404                         0.251797  \n",
       "4            0.710344                         0.243100  \n",
       "5            0.591270                         0.229979  \n",
       "6            0.515542                         0.211883  \n",
       "7            0.481191                         0.199439  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v1.score_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-7 Hit Ratios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.8005609</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.982719</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9975644</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9995369</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9999914</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.800561\n",
       "2    0.982719\n",
       "3    0.997564\n",
       "4    0.999537\n",
       "5    0.999991\n",
       "6    1\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v1.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This default GBM is much worse than our original random forest.  \n",
    "\n",
    "\n",
    "The GBM is far from converging, so there are three primary knobs to adjust to get our performance up if we want to keep a similar run time.  \n",
    "\n",
    "1: Adding trees will help. The default is 50.  \n",
    "2: Increasing the learning rate will also help. The contribution of each tree will be stronger, so the model will move further away from the overall mean.  \n",
    "3: Increasing the depth will help. This is the parameter that is the least straightforward. Tuning trees and learning rate both have direct impact that is easy to understand. Changing the depth means you are adjusting the \"weakness\" of each learner. Adding depth makes each tree fit the data closer.  \n",
    "  \n",
    "The first configuration will attack depth the most, since we've seen the random forest focus on a continuous variable (elevation) and 40-class factor (soil type) the most.  \n",
    "\n",
    "Also we will take a look at how to review a model while it is running.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###GBM Round 2\n",
    "\n",
    "Let's do the following:\n",
    "\n",
    "1. decrease the number of trees to speed up runtime(from default 50 to 20)\n",
    "2. increase the learning rate (from default 0.1 to 0.2)\n",
    "3. increase the depth (from default 5 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##############################                    ] 60%"
     ]
    }
   ],
   "source": [
    "gbm_v2 = H2OGradientBoostingEstimator(\n",
    "    ntrees=20,\n",
    "    learn_rate=0.2,\n",
    "    max_depth=10,\n",
    "    stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v2\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Live Performance Monitoring\n",
    "\n",
    "While this is running, we can actually look at the model. To do this we simply need a new connection to H2O. \n",
    "\n",
    "This Python notebook will run the model, so we need either another notebook or the web browser (or R, etc.). In this demo, we will use [Flow](http://localhost:54321) in our web browser http://localhost:54321 and the focus will be to look at model performance, since we are using Python to control H2O. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has moved us in the right direction, but still lower accuracy than the random forest.  \n",
    "\n",
    "It still has yet to converge, so we can make it more aggressive.  \n",
    "\n",
    "We can now add the stochastic nature of random forest into the GBM using some of the new H2O settings. This will help generalize and also provide a quicker runtime, so we can add a few more trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree V3\n",
    "\n",
    "1. Add a few trees(from 20 to 30)\n",
    "2. Increase learning rate (to 0.3)\n",
    "3. Use a random 70% of rows to fit each tree\n",
    "4. Use a random 70% of columns to fit each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_v3 = H2OGradientBoostingEstimator(\n",
    "    ntrees=30,\n",
    "    learn_rate=0.3,\n",
    "    max_depth=10,\n",
    "    sample_rate=0.7,\n",
    "    col_sample_rate=0.7,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v3\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v3.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_v3.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Parity\n",
    "\n",
    "Now the GBM is close to the initial random forest.\n",
    "\n",
    "However, we used a default random forest. Random forest's primary strength is how well it runs with standard parameters, and while there are only a few parameters to tune, we can experiment with those to see if it will make a difference.  \n",
    "\n",
    "The main parameters to tune are the tree depth and the mtries, which is the number of predictors to use.  \n",
    "\n",
    "The default depth of trees is 20. It is common to increase this number, to the point that in some implementations, the depth is unlimited. We will increase ours from 20 to 30.  \n",
    "\n",
    "Note that the default mtries depends on whether classification or regression is being run. The default for classification is one-third of the columns. The default for regression is the square root of the number of columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_v2 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v2\",\n",
    "    ntrees=200,\n",
    "    max_depth=30,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01,\n",
    "    score_each_iteration=True,\n",
    "    seed=3000000)\n",
    "rf_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Final Predictions\n",
    "\n",
    "Now that we have our validation accuracy up beyond 95%, we can start considering our test data.  \n",
    "We have withheld an extra test set to ensure that after all the parameter tuning we have repeatedly applied with the validation data, we still have a completely pristine data set upon which to test the predictive capacity of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Excludes the \"Cover_Type\" column from the features provided\n",
    "final_rf_predictions = rf_v2.predict(test[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, our model won't look at the [\"Cover_Type\"] column within the test data, as it is trained on a set of features not including \"Cover_Type\". It is up to the user whether to include it in the test frame provided for predictions, as it has no effect whatsoever.\n",
    "\n",
    "Let's take a peek at the first few rows of predictions returned by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_rf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these predictions to the accuracy we got from our experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#validation set accuracy\n",
    "rf_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test set accuracy\n",
    "(final_rf_predictions['predict']==test['Cover_Type']).as_data_frame(use_pandas=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final error rates are very similar between validation and test sets. This suggests that we did not overfit the validation set during our experimentation. This concludes our demo of H2O GBM and H2O Random Forests.\n",
    "\n",
    "\n",
    "###Shut down the cluster\n",
    "Shut down the cluster now that we are done using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Possible Further Steps\n",
    "\n",
    "Model-agnostic gains can be found in improving handling of categorical features. We could experiment with the nbins and nbins_cats settings to control the H2O splitting.The general guidance is to lower the number to increase generalization (avoid overfitting), increase to better fit the distribution.  \n",
    " \n",
    "A good example of adjusting this value is for nbins_cats to be increased to match the number of values in a category. Though usually unnecessary, this can improve performance if a problem has a very important categorical predictor.  \n",
    "\n",
    "\n",
    "With regards to our Random Forest, we could further experiment with deeper trees or a higher percentage of columns used (mtries).  \n",
    "\n",
    "The GBM can be set to converge a slower for optimal accuracy. If we were to relax our runtime requirements a little bit, we could balance the learn rate and number of trees used.  \n",
    "\n",
    "In a production setting where fine-grain accuracy is beneficial, it is common to set the learn rate to a very small number, such as 0.01 or smaller, and add trees to match.  \n",
    "\n",
    "Use of early stopping is very powerful in allowing the setting of a low learning rate and the building as many trees as needed until the desired convergence is met."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
